{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection , linear_model, metrics, pipeline,tree, preprocessing,neighbors,ensemble,svm,naive_bayes\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,train_test_split,RandomizedSearchCV,cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "import random\n",
    "from sklearn.feature_selection import SelectKBest,chi2,mutual_info_classif\n",
    "\n",
    "#from sklearn import model_selection import grid_search\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from itertools import *\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data = pd.read_csv('./data/train.csv')\n",
    "original_test_data = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data,mode): \n",
    "    \n",
    "    #Обработка пропусков\n",
    "    #Заполняем медианой\n",
    "    #raw_data.Age = raw_data.Age.fillna(raw_data.Age.median())\n",
    "    #Заполняем медианой c группировкой\n",
    "    raw_data=data.copy()\n",
    "    grp = raw_data.groupby(['Sex', 'Pclass'])  \n",
    "    raw_data.Age = grp.Age.apply(lambda x: x.fillna(x.median()))\n",
    "    #Заполняем модой\n",
    "    #raw_data.Embarked = raw_data.Embarked.fillna(raw_data.Embarked.value_counts().idxmax())\n",
    "    raw_data.Embarked.fillna(raw_data.Embarked.mode()[0], inplace = True)\n",
    "    raw_data.Fare.fillna(raw_data.Fare.mode()[0],inplace = True)\n",
    "    #Заполняем 'N'\n",
    "    raw_data.Cabin = raw_data.Cabin.fillna('NA')\n",
    "\n",
    "    \n",
    "    if mode=='new_features':\n",
    "        print('--new_features mode--')\n",
    "        #raw_data.Embarked.value_counts()\n",
    "        #добавим новые признаки\n",
    "        raw_data['Family'] = raw_data.Parch + raw_data.SibSp+1\n",
    "        raw_data['Family_Size'] = pd.cut(raw_data.Family, [0,1.5,4.5,15],labels=['Single','SmallFamily','LargeFamily'])\n",
    "        #raw_data['Is_Alone'] = (raw_data.Family == 0).astype(int)\n",
    "        raw_data['Salutation'] = raw_data.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip()) \n",
    "        raw_data['Age_Range'] = pd.cut(raw_data.Age, [0, 10, 20, 30, 40, 50, 60,70,80])\n",
    "        raw_data['Fare_Category'] = pd.cut(raw_data.Fare, bins=[0,7.90,14.45,31.28,120.0,513.0],include_lowest = True, labels=['Low','Mid','High_Mid','High','Upper_High'])\n",
    "        raw_data['isCabin']=raw_data.Cabin.apply(lambda x: 1 if x != 'NA' else 0)\n",
    "        np.seterr(divide = 'ignore')\n",
    "        raw_data['Log_Fare']=np.log10(raw_data.Fare).replace(-np.inf, 0)\n",
    "        #raw_train_data.iloc[np.where(raw_train_data.Log_Fare.values<np.finfo(np.float64).min)]\n",
    "        #raw_data['Fare_Category'] = pd.cut(raw_data['Fare'], bins=[0,7.90,14.45,31.28,120.0], labels=['Low','Mid','High_Mid','High'])\n",
    "        #raw_data['Fare_Category'] = pd.cut(raw_data['Fare'], [0,7.90,14.45,31.28,120.0,513.0],include_lowest = True)\n",
    "        #raw_data.Salutation.nunique()\n",
    "        #####################New features#####################\n",
    "        name_dict = {\"Capt\":       \"officer\",\n",
    "                     \"Col\":        \"officer\",\n",
    "                     \"Major\":      \"officer\",\n",
    "                     \"Dr\":         \"officer\",\n",
    "                     \"Rev\":        \"officer\",\n",
    "                     \"Jonkheer\":   \"snob\",\n",
    "                     \"Don\":        \"snob\",\n",
    "                     \"Sir\" :       \"snob\",\n",
    "                     \"the Countess\":\"snob\",\n",
    "                     \"Dona\":       \"snob\",\n",
    "                     \"Lady\" :      \"snob\",\n",
    "                     \"Mme\":        \"married\",\n",
    "                     \"Ms\":         \"married\",\n",
    "                     \"Mrs\" :       \"married\",\n",
    "                     \"Miss\" :      \"single\",\n",
    "                     \"Mlle\":       \"single\",\n",
    "                     \"Mr\" :        \"man\",\n",
    "                     \"Master\" :    \"boy\"\n",
    "                    }\n",
    "        raw_data['Salutation_type'] = raw_data['Salutation'].map(name_dict)\n",
    "        \n",
    "        #fictitious uniform features\n",
    "        color = ['red','blue','green','yellow','orange','black','black']\n",
    "        color_sampling = random.choices(color, k=raw_data.shape[0])\n",
    "        raw_data['Color']=color_sampling \n",
    "        \n",
    "    else:\n",
    "        print('--Original mode--')\n",
    "        pass\n",
    "        \n",
    "    return raw_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(numeric_data_indices,categorical_data_indices,classifier):\n",
    "    estimator = pipeline.Pipeline(steps = [       \n",
    "        (\n",
    "            'feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                #binary\n",
    "                #('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "                        \n",
    "                #numeric\n",
    "                ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                    ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices],validate=False)),\n",
    "                    ('scaling', preprocessing.StandardScaler())            \n",
    "                            ])),\n",
    "        \n",
    "                #categorical\n",
    "                ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "                    ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices],validate=False)),\n",
    "                    ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown = 'ignore',sparse=False))            \n",
    "                            ])),\n",
    "            ])\n",
    "        ),\n",
    "        ('model_fitting', classifier)\n",
    "        ]\n",
    "    )\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--new_features mode--\n"
     ]
    }
   ],
   "source": [
    "#Подготовка с отбором признаков\n",
    "\n",
    "#exclude_col = ['Name', 'Embarked', 'Cabin', 'isCabin','Salutation', 'Sex', 'Family']\n",
    "#['Name', 'Embarked', 'Cabin', 'isCabin'] ['Salutation', 'Sex', 'Family']\n",
    "#prepare_data(raw_train_data,[])\n",
    "\n",
    "\n",
    "\n",
    "train_data=prepare_data(original_train_data,'new_features')\n",
    "\n",
    "train_labels = train_data['Survived']\n",
    "train_data.drop(['PassengerId', 'Survived'], axis = 1,inplace=True)\n",
    "all_column=train_data.columns\n",
    "#Описание колонок и индексов для FeatureUnion\n",
    "string_data_columns = ['Name','Ticket','Cabin']\n",
    "categorical_data_columns = ['Pclass','Sex','Embarked','Salutation','Age_Range', 'Fare_Category','Family_Size','Salutation_type','Color']\n",
    "numeric_data_columns = ['Age', 'SibSp', 'Parch', 'Fare','Family','isCabin','Log_Fare']\n",
    "categorical_data_indices = np.array([(column in categorical_data_columns) for column in train_data.columns], dtype = bool)\n",
    "numeric_data_indices = np.array([(column in numeric_data_columns) for column in train_data.columns], dtype = bool)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "correlation = df_trans.corr()\n",
    "plt.figure(figsize=(16, 5))\n",
    "heatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-0.75, vmax=0.75, cmap=\"RdBu_r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>Age_Range</th>\n",
       "      <th>Fare_Category</th>\n",
       "      <th>isCabin</th>\n",
       "      <th>Log_Fare</th>\n",
       "      <th>Salutation_type</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(20, 30]</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860338</td>\n",
       "      <td>man</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>1.852988</td>\n",
       "      <td>married</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(20, 30]</td>\n",
       "      <td>Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>0.898999</td>\n",
       "      <td>single</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>1.725095</td>\n",
       "      <td>married</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905796</td>\n",
       "      <td>man</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  Family  \\\n",
       "0      1      0         A/5 21171   7.2500    NA        S       2   \n",
       "1      1      0          PC 17599  71.2833   C85        C       2   \n",
       "2      0      0  STON/O2. 3101282   7.9250    NA        S       1   \n",
       "3      1      0            113803  53.1000  C123        S       2   \n",
       "4      0      0            373450   8.0500    NA        S       1   \n",
       "\n",
       "   Family_Size Salutation Age_Range Fare_Category  isCabin  Log_Fare  \\\n",
       "0  SmallFamily         Mr  (20, 30]           Low        0  0.860338   \n",
       "1  SmallFamily        Mrs  (30, 40]          High        1  1.852988   \n",
       "2       Single       Miss  (20, 30]           Mid        0  0.898999   \n",
       "3  SmallFamily        Mrs  (30, 40]          High        1  1.725095   \n",
       "4       Single         Mr  (30, 40]           Mid        0  0.905796   \n",
       "\n",
       "  Salutation_type  Color  \n",
       "0             man  green  \n",
       "1         married   blue  \n",
       "2          single  black  \n",
       "3         married   blue  \n",
       "4             man   blue  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "black     251\n",
       "blue      140\n",
       "red       139\n",
       "green     136\n",
       "orange    114\n",
       "yellow    111\n",
       "Name: Color, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.loc[:,categorical_data_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_select_estimator(numeric_data_indices,categorical_data_indices,classifier):\n",
    "\n",
    "    estimator = pipeline.Pipeline(steps = [       \n",
    "            (\n",
    "                'feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                    #binary\n",
    "                    #('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "\n",
    "                    #numeric\n",
    "                    ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices],validate=False)),\n",
    "                        ('scaling', preprocessing.StandardScaler())            \n",
    "                                ])),\n",
    "\n",
    "                    #categorical\n",
    "                    ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices],validate=False)),\n",
    "                        ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown = 'ignore',sparse=False))            \n",
    "                                ])),\n",
    "                ])\n",
    "            ),\n",
    "            #('rfecv', RFECV(estimator=clf, scoring='accuracy')) #RFE\n",
    "            ('rfe', RFE(estimator=classifier, ))\n",
    "\n",
    "            ]\n",
    "        )\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_column=numeric_data_columns+list(grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[1][1].get_feature_names())\n",
    "#coef=grid_cv.best_estimator_.steps[1][1].coef_[0]\n",
    "#sorted(zip(np.abs(coef),all_column),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {'SVC':svm.SVC(kernel=\"linear\"),'LR':linear_model.LogisticRegression(solver='lbfgs'),\n",
    "                   'DeTree':tree.DecisionTreeClassifier(),\n",
    "                   'GB':ensemble.GradientBoostingClassifier()}\n",
    "n=1\n",
    "result_df_list= []\n",
    "for k, v in classifier_dict.items():\n",
    "    RFE_est=create_select_estimator(numeric_data_indices,categorical_data_indices,v)\n",
    "    RFE_est.fit(train_data.values, train_labels)\n",
    "    \n",
    "    #clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,v)\n",
    "    all_column=numeric_data_columns+list(RFE_est.named_steps['feature_processing'].transformer_list[1][1].named_steps['hot_encoding'].get_feature_names())\n",
    "    clf_list=[k]*len(all_column)\n",
    "    #coef=list(RFE_est.named_steps['rfe'].estimator_.coef_[0])\n",
    "    #coef_list=zip(np.abs(coef),all_column)\n",
    "    #RFE_est.named_steps['rfe'].ranking_\n",
    "    rank=list(RFE_est.named_steps['rfe'].ranking_)\n",
    "    rank_list = sorted(zip(rank,all_column))\n",
    "    support=list(RFE_est.named_steps['rfe'].support_)\n",
    "    support_list = sorted(zip(support,all_column))\n",
    "    #RFE_list=list(zip(all_column,coef,rank,support))\n",
    "    RFE_df=pd.DataFrame({'clf'+str(n):clf_list,'F_name'+str(n):all_column,'rank'+str(n):rank,'support'+str(n):support})\n",
    "    #result_df= pd.concat([df1, df4], axis=1)\n",
    "    result_df_list.append(RFE_df)\n",
    "    n+=1\n",
    "result_df= pd.concat(result_df_list, axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[(result_df['support1']==False) & (result_df['support2']==False) & (result_df['support3']==False) & (result_df['support4']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_RFE=result_df.sort_values(by=['rank1','F_name1'],ascending=True)\n",
    "#select_RFE.to_csv('select_RFE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features SVC - exclude ['Parch','Age_Range','Embarked','isCabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RFECV_estimator(numeric_data_indices,categorical_data_indices,classifier):\n",
    "\n",
    "    estimator = pipeline.Pipeline(steps = [       \n",
    "            (\n",
    "                'feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                    #binary\n",
    "                    #('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "\n",
    "                    #numeric\n",
    "                    ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices],validate=False)),\n",
    "                        ('scaling', preprocessing.StandardScaler())            \n",
    "                                ])),\n",
    "\n",
    "                    #categorical\n",
    "                    ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices],validate=False)),\n",
    "                        ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown = 'ignore',sparse=False))            \n",
    "                                ])),\n",
    "                ])\n",
    "            ),\n",
    "            ('rfecv', RFECV(estimator=classifier, step=1, cv=model_selection.StratifiedKFold(3),scoring='accuracy'))\n",
    "\n",
    "            ]\n",
    "        )\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {'SVC':svm.SVC(kernel=\"linear\"),'LR':linear_model.LogisticRegression(solver='lbfgs'),\n",
    "                   'DeTree':tree.DecisionTreeClassifier(),'GB':ensemble.GradientBoostingClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "result_df_list= []\n",
    "for k, v in classifier_dict.items():\n",
    "    RFECV_estimator=create_RFECV_estimator(numeric_data_indices,categorical_data_indices,v)\n",
    "    #RFE_est=create_select_estimator(numeric_data_indices,categorical_data_indices,v)\n",
    "    RFECV_estimator.fit(train_data.values, train_labels)\n",
    "    all_column=numeric_data_columns+list(RFECV_estimator.named_steps['feature_processing'].transformer_list[1][1].named_steps['hot_encoding'].get_feature_names())\n",
    "    features_index=RFECV_estimator.named_steps['rfecv'].support_\n",
    "    features_rank=RFECV_estimator.named_steps['rfecv'].ranking_\n",
    "    score_list=list(RFECV_estimator.named_steps['rfecv'].grid_scores_)\n",
    "    clf_list=[k]*len(features_index)\n",
    "    #print('Num Features: ',RFECV_estimator.named_steps['rfecv'].n_features_)\n",
    "    #print('Selected Features:', features_index)\n",
    "    #print('Feature Ranking:', features_rank)\n",
    "    #print('Feature Coef:', RFECV_estimator.named_steps['rfecv'].estimator_.coef_)\n",
    "    RFECV_df=pd.DataFrame({'clf':clf_list,'F_name':all_column,'rank':features_rank,'support':features_index,'score':score_list})\n",
    "    result_df_list.append(RFECV_df)\n",
    "    print('Optimal number of features :', RFECV_estimator.named_steps['rfecv'].n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    #plt.title('clf='+k)\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    fig.suptitle('clf='+k)\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(RFECV_estimator.named_steps['rfecv'].grid_scores_) + 1), RFECV_estimator.named_steps['rfecv'].grid_scores_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFECV_df.sort_values(by=['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hi^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df=pd.get_dummies(train_data.loc[:,categorical_data_indices],\n",
    "               prefix=['Pclass','Sex','Embarked','Family_Size','Salutation','Age_Range','Fare_Category','Salutation_type','Color'],\n",
    "                      columns = ['Pclass','Sex','Embarked','Family_Size','Salutation','Age_Range','Fare_Category','Salutation_type','Color']\n",
    "                     )\n",
    "prepared_train_data=pd.concat([train_data.loc[:,numeric_data_indices], cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fare, isCabin, Pclass_1, Sex_female, Sex_male, Family_Size_SmallFamily, Salutation_Miss, Salutation_Mr, Salutation_Mrs, Salutation_type_man, Salutation_type_married, Salutation_type_single\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest(chi2,k=12)\n",
    "X_new = select.fit_transform(prepared_train_data, train_labels)\n",
    "# all_column\n",
    "names=prepared_train_data.columns\n",
    "#ames = count_vectorizer.get_feature_names()\n",
    "selected_words = names[select.get_support()]\n",
    "print(', '.join(selected_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "MI=mutual_info_classif(prepared_train_data, train_labels, discrete_features=True)\n",
    "MI_df=pd.DataFrame({'features':names,'MI':MI,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.302990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Log_Fare</td>\n",
       "      <td>0.302990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Salutation_type_man</td>\n",
       "      <td>0.156852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Salutation_Mr</td>\n",
       "      <td>0.156852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>0.150870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>0.150870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.101624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Salutation_type_married</td>\n",
       "      <td>0.059130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Salutation_Mrs</td>\n",
       "      <td>0.057065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Salutation_type_single</td>\n",
       "      <td>0.054386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.052536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Salutation_Miss</td>\n",
       "      <td>0.052502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>isCabin</td>\n",
       "      <td>0.049270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Family</td>\n",
       "      <td>0.047781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>0.040061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Family_Size_SmallFamily</td>\n",
       "      <td>0.038738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Fare_Category_Low</td>\n",
       "      <td>0.026308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.023197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Family_Size_Single</td>\n",
       "      <td>0.020593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Fare_Category_High</td>\n",
       "      <td>0.017834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.016366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.013803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Fare_Category_Upper_High</td>\n",
       "      <td>0.011449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.011028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Family_Size_LargeFamily</td>\n",
       "      <td>0.008807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    features        MI\n",
       "3                       Fare  0.302990\n",
       "6                   Log_Fare  0.302990\n",
       "49       Salutation_type_man  0.156852\n",
       "29             Salutation_Mr  0.156852\n",
       "10                Sex_female  0.150870\n",
       "11                  Sex_male  0.150870\n",
       "0                        Age  0.101624\n",
       "50   Salutation_type_married  0.059130\n",
       "30            Salutation_Mrs  0.057065\n",
       "52    Salutation_type_single  0.054386\n",
       "9                   Pclass_3  0.052536\n",
       "26           Salutation_Miss  0.052502\n",
       "5                    isCabin  0.049270\n",
       "4                     Family  0.047781\n",
       "7                   Pclass_1  0.040061\n",
       "16   Family_Size_SmallFamily  0.038738\n",
       "43         Fare_Category_Low  0.026308\n",
       "1                      SibSp  0.023197\n",
       "15        Family_Size_Single  0.020593\n",
       "46        Fare_Category_High  0.017834\n",
       "2                      Parch  0.016366\n",
       "12                Embarked_C  0.013803\n",
       "47  Fare_Category_Upper_High  0.011449\n",
       "14                Embarked_S  0.011028\n",
       "17   Family_Size_LargeFamily  0.008807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_df.sort_values('MI',ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0, 0],\n",
    "              [1, 1, 0],\n",
    "              [2, 0, 1],\n",
    "              [2, 0, 1],\n",
    "              [2, 0, 1]])\n",
    "y = np.array([0, 1, 2, 2, 1])\n",
    "mi1=mutual_info_classif(X, y, discrete_features=True)\n",
    "# result: array([ 0.67301167,  0.22314355,  0.39575279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67301167, 0.22314355, 0.39575279])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  0\n",
       "0  0  0  0  0\n",
       "1  1  1  0  1\n",
       "2  2  0  1  2\n",
       "3  2  0  1  2\n",
       "4  2  0  1  1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.concat([pd.DataFrame(X), pd.DataFrame(y)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69314718])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mutual_info_classif([[1],[0]], [1,0], discrete_features=True)\n",
    "# result: array([ 0.67301167,  0.22314355,  0.39575279]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перебор подмножеств признаков n<=5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier_dict = {'RiC':linear_model.RidgeClassifier(),'SVC':svm.SVC(gamma='auto'),'SGD':linear_model.SGDClassifier(),'LR':linear_model.LogisticRegression(solver='lbfgs'),\n",
    "                   'KNC':neighbors.KNeighborsClassifier(),'DeTree':tree.DecisionTreeClassifier(),\n",
    "                   'RF':ensemble.RandomForestClassifier(n_estimators=10),'GB':ensemble.GradientBoostingClassifier(),\n",
    "                   'BG':ensemble.BaggingClassifier(),'NB':naive_bayes.GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num Features: %d',estimator.named_steps['rfe'].n_features_)\n",
    "print('Selected Features:', estimator.named_steps['rfe'].support_)\n",
    "print('Feature Ranking:', estimator.named_steps['rfe'].ranking_)\n",
    "print('Feature Coef:', estimator.named_steps['rfe'].estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier_dict = {'RiC':linear_model.RidgeClassifier(),'SVC':svm.SVC(gamma='auto') ,'RF':ensemble.RandomForestClassifier(n_estimators=10),'GB':ensemble.GradientBoostingClassifier(),'KNC':neighbors.KNeighborsClassifier(),'DeTree':tree.DecisionTreeClassifier()}\n",
    "classifier_dict = {'GB':ensemble.GradientBoostingClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сочетание без повторений\n",
    "combinations_features_1=[[x] for x in all_column]\n",
    "print('len combinations_features_1:',len(combinations_features_1))\n",
    "combinations_features_2=[list(set().union(*x)) for x in combinations(combinations_features_1, 2)]\n",
    "print('len combinations_features_2:',len(combinations_features_2))\n",
    "combinations_features_3=[list(set().union(*x)) for x in combinations(combinations_features_1, 3)]\n",
    "print('len combinations_features_3:',len(combinations_features_3))\n",
    "combinations_features_4=[list(set().union(*x)) for x in combinations(combinations_features_1, 4)]\n",
    "print('len combinations_features_4:',len(combinations_features_4))\n",
    "#combinations_features_5=[list(set().union(*x)) for x in combinations(combinations_features_1, 5)]\n",
    "#print('len combinations_features_5:',len(combinations_features_5))\n",
    "combinations_features_all=[[]]+combinations_features_1+combinations_features_2+\\\n",
    "combinations_features_3+combinations_features_4#+combinations_features_5\n",
    "print('len combinations_features_all:',len(combinations_features_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Перебор изъятия признаков\n",
    "\n",
    "\n",
    "exclude_col_list=[]\n",
    "clf_res_list=[]\n",
    "#cv_res_list=[]\n",
    "mean_res_list=[]\n",
    "max_res_list=[]\n",
    "min_res_list=[]\n",
    "std_res_list=[]\n",
    "#test_acc=[]\n",
    "#for exclude_col in all_column:\n",
    "for exclude_col in combinations_features_all:\n",
    "    #exclude_col=list(set().union(*exclude_col_tup))\n",
    "    #print(exclude_col)\n",
    "    \n",
    "    current_train_data=train_data.copy()\n",
    "    current_train_data.drop(exclude_col, axis = 1,inplace=True)\n",
    "    current_categorical_data_indices = np.array([(column in categorical_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "    current_numeric_data_indices = np.array([(column in numeric_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "\n",
    "    for k, v in classifier_dict.items():\n",
    "        #print(\"Code : {0}, Value : {1}\".format(k, v))\n",
    "        #print('***Classifier*****',k)\n",
    "        clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,v)\n",
    "        clf_scoring = cross_val_score(clf, current_train_data.values, train_labels, scoring = 'accuracy', cv = 3)\n",
    "            #print ('mean:{}, max:{}, min:{}, std:{}'.format(clf_scoring.mean(), clf_scoring.max(), clf_scoring.min(), clf_scoring.std()))\n",
    "        exclude_col_list.append(exclude_col)   \n",
    "        clf_res_list.append(k)\n",
    "        #cv_res_list.append(name)\n",
    "        mean_res_list.append(clf_scoring.mean())\n",
    "        max_res_list.append(clf_scoring.max())\n",
    "        min_res_list.append(clf_scoring.min())\n",
    "        std_res_list.append(clf_scoring.std())\n",
    "        #clf.fit(X_train, y_train)\n",
    "        #y_pred=clf.predict(X_test)\n",
    "        #test_acc.append(accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df=pd.DataFrame({'ex_col':exclude_col_list,'clf':clf_res_list,'mean':mean_res_list,'max':max_res_list,'min':min_res_list,'std':std_res_list})\n",
    "select_f_df.sort_values(by=['mean'],ascending=False)#.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df.sort_values(by=['mean'],ascending=False)#.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select_f_df.to_csv('select_f_df_origin')\n",
    "select_f_df.nlargest(10, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df_max_10_mean=select_f_df[select_f_df.clf=='GB'].nlargest(10, 'mean').copy()\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='KNC'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='DeTree'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='DeTree'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='RF'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='SVC'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='RiC'].nlargest(10, 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df[select_f_df.clf=='SVC'].nlargest(10, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df_max_10_mean.groupby(['clf']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df_max_10_mean.sort_values(by=['mean'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подготовка с отбором признаков\n",
    "#exclude_col=['Age', 'Family_Size', 'Salutation', 'Fare_Category']\n",
    "#features SVC - exclude \n",
    "exclude_col=['Parch','Age_Range','Embarked','isCabin']\n",
    "#exclude_col = ['Name', 'Embarked', 'Cabin', 'isCabin','Salutation', 'Sex', 'Family']\n",
    "#['Name', 'Embarked', 'Cabin', 'isCabin'] ['Salutation', 'Sex', 'Family']\n",
    "#prepare_data(raw_train_data,[])\n",
    "\n",
    "#current_train_data=original_train_data.copy()\n",
    "#prepare_data(current_train_data,exclude_col)\n",
    "#train_labels = raw_train_data['Survived']\n",
    "#current_train_data = current_train_data.drop(['PassengerId', 'Survived'], axis = 1)\n",
    "#print(current_train_data.columns)\n",
    "#current_categorical_data_indices = np.array([(column in categorical_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "#current_numeric_data_indices = np.array([(column in numeric_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "#clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,v)\n",
    "#clf_scoring = cross_val_score(clf, current_train_data.values, train_labels, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "current_train_data=train_data.copy()\n",
    "current_train_data.drop(exclude_col, axis = 1,inplace=True)\n",
    "current_categorical_data_indices = np.array([(column in categorical_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "current_numeric_data_indices = np.array([(column in numeric_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(current_train_data.values, train_labels, test_size=0.33,shuffle=True, random_state=42)\n",
    "#stratify=train_labels\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=prepare_data(original_test_data,'new_features')\n",
    "#current_train_data=original_train_data.copy()\n",
    "#prepare_data(current_train_data,'',exclude_col)\n",
    "#train_labels = train_data['Survived']\n",
    "test_data.drop(['PassengerId']+exclude_col, axis = 1,inplace=True)\n",
    "all_column_test=test_data.columns\n",
    "#Описание колонок и индексов для FeatureUnion\n",
    "#Колонки\n",
    "#Проверка пропусков\n",
    "NAs = pd.concat([test_data.isnull().sum()], axis=1, keys=['data'])\n",
    "print('Проверка пропусков',NAs[NAs.sum(axis=1) > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### оценка алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кросс валидация cтратегии\n",
    "cv_strategy_SKF = model_selection.StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "cv_strategy_KF =model_selection.KFold(n_splits=5, shuffle = True, random_state = 0)\n",
    "cv_strategy_ShS =model_selection.ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,random_state=0)\n",
    "cv_strategy_ShS =model_selection.StratifiedShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,random_state=0)\n",
    "cv_dict = {'SKF':cv_strategy_SKF,'KF':cv_strategy_KF,'ShS':cv_strategy_ShS,'ShS':cv_strategy_ShS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {'RiC':linear_model.RidgeClassifier(),'SVC':svm.SVC(gamma='auto'),'SGD':linear_model.SGDClassifier(),'LR':linear_model.LogisticRegression(solver='lbfgs'),\n",
    "                   'KNC':neighbors.KNeighborsClassifier(),'DeTree':tree.DecisionTreeClassifier(),\n",
    "                   'RF':ensemble.RandomForestClassifier(n_estimators=10),'GB':ensemble.GradientBoostingClassifier(),\n",
    "                   'BG':ensemble.BaggingClassifier(),'NB':naive_bayes.GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# кросс валидация оценка\n",
    "\n",
    "clf_res_list=[]\n",
    "cv_res_list=[]\n",
    "mean_res_list=[]\n",
    "max_res_list=[]\n",
    "min_res_list=[]\n",
    "std_res_list=[]\n",
    "test_acc=[]\n",
    "for k, v in classifier_dict.items():\n",
    "    #print(\"Code : {0}, Value : {1}\".format(k, v))\n",
    "    print('***Classifier*****',k)\n",
    "    clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,v)\n",
    "    for name,val in cv_dict.items():\n",
    "        clf_scoring = cross_val_score(clf, X_train, y_train, scoring = 'accuracy', cv = val)\n",
    "        print('--cv--',name,'----',val)\n",
    "        #print ('mean:{}, max:{}, min:{}, std:{}'.format(clf_scoring.mean(), clf_scoring.max(), clf_scoring.min(), clf_scoring.std()))\n",
    "        clf_res_list.append(k)\n",
    "        cv_res_list.append(name)\n",
    "        mean_res_list.append(clf_scoring.mean())\n",
    "        max_res_list.append(clf_scoring.max())\n",
    "        min_res_list.append(clf_scoring.min())\n",
    "        std_res_list.append(clf_scoring.std())\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        test_acc.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_table=pd.DataFrame({'clf':clf_res_list, 'cv':cv_res_list,'mean':mean_res_list,'max':max_res_list,'min':min_res_list,'std':std_res_list,'test_acc':test_acc})\n",
    "res_table.sort_values(by=['test_acc'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD\n",
    "#RidgeClassifier\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__alpha' : [1e-3, 1e-2, 1e-1, 1,1e1,1e2], #RC\n",
    "    #'model_fitting__kernel' : ['linear', 'poly', 'rbf', 'sigmoid'], #GB\n",
    "    #'model_fitting__class_weight' : [None,'balanced'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,linear_model.RidgeClassifier(fit_intercept=False))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#grid_cv.fit(train_data.values, train_labels)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grid_cv.best_estimator_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Коэфициенты модели\n",
    "#grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[0][1].fit_transform(X_train)[:2]\n",
    "#one_hot_cat_col=grid_cv.best_estimator_.steps[0][1].transformer_list[1][1][1].get_feature_names(categorical_data_columns)\n",
    "#grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[1][1].categories_\n",
    "all_column=numeric_data_columns+list(grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[1][1].get_feature_names())\n",
    "coef=grid_cv.best_estimator_.steps[1][1].coef_[0]\n",
    "sorted(zip(np.abs(coef),all_column),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__C' : [0.01,0.1, 1, 10, 100,], \n",
    "    #'model_fitting__C' : [0.8, 0.85, 0.9],\n",
    "    'model_fitting__kernel' : ['linear','rbf', 'sigmoid'], \n",
    "    'model_fitting__class_weight' : [None,'balanced'],\n",
    "    'model_fitting__decision_function_shape':['ovo', 'ovr'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,svm.SVC())\n",
    "cv = model_selection.KFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv,iid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=40,iid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8359550561797753\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__decision_function_shape': 'ovo', 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 7.8 s, sys: 0 ns, total: 7.8 s\n",
    "Wall time: 7.8 s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8368263473053892\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__decision_function_shape': 'ovo', 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 18.8 s, sys: 39.8 ms, total: 18.9 s\n",
    "Wall time: 18.9 s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8368263473053892\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 1min 40s, sys: 2.51 ms, total: 1min 40s\n",
    "Wall time: 1min 40s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8327721661054994\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 40.1 s, sys: 0 ns, total: 40.1 s\n",
    "Wall time: 40.1 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoosting\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__n_estimators' : [3,4, 8, 16, 32, 64, 100], #GB\n",
    "    'model_fitting__max_depth' : [3,5,7], #GB\n",
    "    #'model_fitting__loss' : [\"deviance\",'exponential'],\n",
    "    'model_fitting__learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 1, 5),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 5),\n",
    "    'model_fitting__max_features':['auto',\"log2\",\"sqrt\",None],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,ensemble.GradientBoostingClassifier())\n",
    "cv = model_selection.KFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv,iid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.851685393258427\n",
    "{'model_fitting__learning_rate': 0.01, 'model_fitting__max_depth': 5, 'model_fitting__max_features': 'log2', 'model_fitting__n_estimators': 100}\n",
    "CPU times: user 1min 9s, sys: 7.85 ms, total: 1min 9s\n",
    "Wall time: 1min 9s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8471910112359551\n",
    "{'model_fitting__n_estimators': 100, 'model_fitting__max_features': 'log2', 'model_fitting__max_depth': 5, 'model_fitting__learning_rate': 0.01}\n",
    "CPU times: user 14.5 s, sys: 3.94 ms, total: 14.5 s\n",
    "Wall time: 14.6 s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8417508417508418\n",
    "{'model_fitting__learning_rate': 0.1, 'model_fitting__max_depth': 5, 'model_fitting__max_features': 'auto', 'model_fitting__n_estimators': 64}\n",
    "CPU times: user 1min 30s, sys: 0 ns, total: 1min 30s\n",
    "Wall time: 1min 30s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8451178451178452\n",
    "{'model_fitting__learning_rate': 0.25, 'model_fitting__max_depth': 5, 'model_fitting__min_samples_leaf': 0.1, 'model_fitting__min_samples_split': 0.325, 'model_fitting__n_estimators': 100}\n",
    "CPU times: user 2min 22s, sys: 320 ms, total: 2min 22s\n",
    "Wall time: 2min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=grid_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__C' : [0.001,0.01,0.1,1,10,100], #GB\n",
    "    #'model_fitting__penalty' : ['l2','l1','none'],\n",
    "    'model_fitting__solver' : ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,linear_model.LogisticRegression(max_iter=1000))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8260381593714927\n",
    "{'model_fitting__C': 10}\n",
    "CPU times: user 928 ms, sys: 16 ms, total: 944 ms\n",
    "Wall time: 478 ms\n",
    "solver='lbfgs',penalty = 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__n_estimators' : [1, 2, 4, 8, 16, 32, 64, 100, 200,500], #GB\n",
    "    #'model_fitting__max_depth' : np.linspace(1, 32, 32, endpoint=True), #GB\n",
    "    #'model_fitting__loss' : [\"deviance\",'exponential'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    'model_fitting__min_samples_split': [2,5,7,10],\n",
    "    'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\",'auto'],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "    #'model_fitting__class_weight' : ['balanced',None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,ensemble.RandomForestClassifier(class_weight='balanced'))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7957351290684624\n",
    "{'model_fitting__n_estimators': 64, 'model_fitting__min_samples_split': 0.2, 'model_fitting__min_samples_leaf': 0.1, 'model_fitting__max_features': 'sqrt', 'model_fitting__max_depth': 2.0}\n",
    "CPU times: user 15.4 s, sys: 136 ms, total: 15.6 s\n",
    "Wall time: 15.6 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение финального классификатора ALL_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__C' : [0.01,0.1, 1, 10, 100,], \n",
    "    #'model_fitting__C' : [0.8, 0.85, 0.9],\n",
    "    'model_fitting__kernel' : ['linear','rbf', 'sigmoid'], \n",
    "    'model_fitting__class_weight' : [None,'balanced'],\n",
    "    'model_fitting__decision_function_shape':['ovo', 'ovr'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,svm.SVC(gamma='auto'))\n",
    "cv = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv,iid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,iid=False,n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(current_train_data.values, train_labels)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8305274971941639\n",
    "{'model_fitting__kernel': 'rbf', 'model_fitting__gamma': 'auto', 'model_fitting__decision_function_shape': 'ovo', 'model_fitting__class_weight': None, 'model_fitting__C': 1}\n",
    "CPU times: user 5.11 s, sys: 0 ns, total: 5.11 s\n",
    "Wall time: 5.11 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### формирование файла Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grid_cv.predict(test_data.values)\n",
    "submission = pd.DataFrame({'PassengerId':original_test_data.PassengerId,'Survived':result})\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "print(submission.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'titanic18_sf_5_SVC.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразование категориальных признаков в отдельном df\n",
    "#dummy_data=pd.get_dummies(data=raw_test_data, columns=categorical_data_columns)\n",
    "#dummy_index=dummy_data.columns.str.contains('|'.join(categorical_data_columns))\n",
    "#dummy_data=dummy_data.loc[:,dummy_index]\n",
    "#Числовые данные в отдельном df\n",
    "#numeric_data=raw_test_data[numeric_data_columns]\n",
    "#создаем стандартный scaler\n",
    "#scaler = StandardScaler()\n",
    "#scaled_test_data=scaler.transform(numeric_data)\n",
    "#scaled_test_data = scaler.transform(test_data)\n",
    "#all_test_data=np.hstack((scaled_test_data,dummy_data.values))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# найти все признаки, в которых первое значение - строка\n",
    "def find_cat(data):\n",
    "    for name in data.columns:\n",
    "        s = ''\n",
    "        s += name\n",
    "        if (type(data[name][0]) == str):\n",
    "            s += ' строка,'\n",
    "        if (data[name].nunique()<=3):\n",
    "            s += ' мало уникальных'\n",
    "        if (s!=name):\n",
    "            print (s)\n",
    "            \n",
    "find_cat(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(train_data.values, train_labels.values, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st.shape,y_train_st.shape,y_train_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.RidgeClassifier(alpha=10.0)\n",
    "#svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')\n",
    "#\n",
    "clfs = [create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.LogisticRegression(solver='liblinear',class_weight=None,tol=1e-05, penalty='l2')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.RidgeClassifier(alpha=10.0)),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,ensemble.GradientBoostingClassifier(learning_rate= 0.1, max_depth= 3, max_features='auto', n_estimators= 32))\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train = np.zeros((X_train_st.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    for i, (train_, test_) in enumerate(kf.split(X_train_st, y_train_st)):\n",
    "        print (\"Fold\", i)\n",
    "        X_tr = X_train_st[train_]\n",
    "        y_tr = y_train_st[train_]\n",
    "        X_te = X_train_st[test_]\n",
    "        y_te = y_train_st[test_]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        print('------------------------',type(clf[1]))\n",
    "        if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "            print('----------SVM/RidgeCl-------')\n",
    "            y_submission = clf.predict(X_te)\n",
    "        else:\n",
    "            print('----------Other-------')\n",
    "            y_submission = clf.predict_proba(X_te)[:, 1]\n",
    "        dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(clf[1],svm.SVC),\n",
    "type(clf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = linear_model.RidgeClassifier(class_weight=None,tol=1e-05, random_state=11)\n",
    "ls = cross_val_score(clf2, dataset_blend_train, y_train_st, cv=5, scoring='accuracy')\n",
    "print(ls)\n",
    "np.mean(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.fit(dataset_blend_train, y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf2.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест для стекинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "X_meta = np.zeros((X_test_st.shape[0],len(clfs)))\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    #for i, (train_, test_) in enumerate(kf.split(train_data, train_labels)):\n",
    "    #    print (\"Fold\", i)\n",
    "    #    X_tr = train_data.values[train_]\n",
    "    #    y_tr = train_labels[train_]\n",
    "    #    X_te = train_data.values[test_]\n",
    "    #    y_te = train_labels[test_]\n",
    "    #    clf_pipeline=create_estimator(numeric_data_indices,categorical_data_indices,clf)\n",
    "    #    clf_pipeline.fit(X_tr, y_tr)\n",
    "    print('------------------------',type(clf[1]))\n",
    "    if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "        print('----------SVM/RidgeCl-------')\n",
    "        #y_submission = clf_.predict(X_te)\n",
    "        X_meta[:, j] = clf.predict(X_test_st)\n",
    "    else:\n",
    "        print('----------Other-------')\n",
    "        #y_submission = clf_pipeline.predict_proba(X_te)[:, 1]\n",
    "        X_meta[:, j] = clf.predict_proba(X_test_st)[:, 1]\n",
    "    #dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape,X_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_meta=clf2.predict(X_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_st, pred_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стекинг для ответа kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.RidgeClassifier(alpha=10.0)\n",
    "#svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')\n",
    "#\n",
    "clfs = [create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.LogisticRegression(solver='liblinear',class_weight=None,tol=1e-05, penalty='l2')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.RidgeClassifier(alpha=10.0)),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,ensemble.GradientBoostingClassifier(learning_rate= 0.1, max_depth= 3, max_features='auto', n_estimators= 32))\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st_kaggle=train_data.values\n",
    "y_train_st_kaggle=train_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train = np.zeros((X_train_st_kaggle.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    for i, (train_, test_) in enumerate(kf.split(X_train_st_kaggle, y_train_st_kaggle)):\n",
    "        print (\"Fold\", i)\n",
    "        X_tr = X_train_st_kaggle[train_]\n",
    "        y_tr = y_train_st_kaggle[train_]\n",
    "        X_te = X_train_st_kaggle[test_]\n",
    "        y_te = y_train_st_kaggle[test_]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        print('------------------------',type(clf[1]))\n",
    "        if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "            print('----------SVM/RidgeCl-------')\n",
    "            y_submission = clf.predict(X_te)\n",
    "        else:\n",
    "            print('----------Other-------')\n",
    "            y_submission = clf.predict_proba(X_te)[:, 1]\n",
    "        dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_kaggle = linear_model.RidgeClassifier(class_weight=None,tol=1e-05, random_state=11)\n",
    "clf_meta_kaggle.fit(dataset_blend_train, y_train_st_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг test для kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st_kaggle=test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "X_meta = np.zeros((X_test_st_kaggle.shape[0],len(clfs)))\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    #for i, (train_, test_) in enumerate(kf.split(train_data, train_labels)):\n",
    "    #    print (\"Fold\", i)\n",
    "    #    X_tr = train_data.values[train_]\n",
    "    #    y_tr = train_labels[train_]\n",
    "    #    X_te = train_data.values[test_]\n",
    "    #    y_te = train_labels[test_]\n",
    "    #    clf_pipeline=create_estimator(numeric_data_indices,categorical_data_indices,clf)\n",
    "    #    clf_pipeline.fit(X_tr, y_tr)\n",
    "    print('------------------------',type(clf[1]))\n",
    "    if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "        print('----------SVM/RidgeCl-------')\n",
    "        #y_submission = clf_.predict(X_te)\n",
    "        X_meta[:, j] = clf.predict(X_test_st_kaggle)\n",
    "    else:\n",
    "        print('----------Other-------')\n",
    "        #y_submission = clf_pipeline.predict_proba(X_te)[:, 1]\n",
    "        X_meta[:, j] = clf.predict_proba(X_test_st_kaggle)[:, 1]\n",
    "    #dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=clf_meta_kaggle.predict(X_meta)\n",
    "submission = pd.DataFrame({'PassengerId':raw_test_data.PassengerId,'Survived':result})\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'titanic16_stack.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data_columns = ['Name','Ticket','Cabin']\n",
    "categorical_data_columns = ['Pclass','Sex','Embarked','Salutation','Age_Range', 'Fare_Category','Family_Size','Salutation_type']\n",
    "numeric_data_columns = ['Age', 'SibSp', 'Parch', 'Fare','Family','isCabin','Log_Fare']\n",
    "#numeric_data_columns = ['Family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
