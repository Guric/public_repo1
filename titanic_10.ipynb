{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection , linear_model, metrics, pipeline,tree, preprocessing,neighbors,ensemble,svm,naive_bayes\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,train_test_split,RandomizedSearchCV,cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#from sklearn import model_selection import grid_search\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = pd.read_csv('./data/train.csv')\n",
    "raw_test_data = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12), (418, 11), 1309)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data.shape,raw_test_data.shape,891+418\n",
    "#raw_train_data_shuffled = raw_train_data.reindex(np.random.permutation(raw_train_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          data\n",
       "Age        177\n",
       "Cabin      687\n",
       "Embarked     2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка пропусков\n",
    "NAs = pd.concat([raw_train_data.isnull().sum()], axis=1, keys=['data'])\n",
    "NAs[NAs.sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(raw_data):\n",
    "    #Обработка пропусков\n",
    "    #Заполняем медианой\n",
    "    #raw_data.Age = raw_data.Age.fillna(raw_data.Age.median())\n",
    "    #Заполняем медианой c группировкой\n",
    "    grp = raw_data.groupby(['Sex', 'Pclass'])  \n",
    "    raw_data.Age = grp.Age.apply(lambda x: x.fillna(x.median()))\n",
    "    #Заполняем модой\n",
    "    #raw_data.Embarked = raw_data.Embarked.fillna(raw_data.Embarked.value_counts().idxmax())\n",
    "    raw_data.Embarked.fillna(raw_data.Embarked.mode()[0], inplace = True)\n",
    "    raw_data.Fare.fillna(raw_data.Fare.mode()[0],inplace = True)\n",
    "    #Заполняем 'N'\n",
    "    raw_data.Cabin = raw_data.Cabin.fillna('NA')\n",
    "\n",
    "    #raw_data.Embarked.value_counts()\n",
    "    #добавим новые признаки\n",
    "    raw_data['Family'] = raw_data.Parch + raw_data.SibSp+1\n",
    "    raw_data['Family_Size'] = pd.cut(raw_data.Family, [0,1.5,4.5,15],labels=['Single','SmallFamily','LargeFamily'])\n",
    "    #raw_data['Is_Alone'] = (raw_data.Family == 0).astype(int)\n",
    "    raw_data['Salutation'] = raw_data.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip()) \n",
    "    raw_data['Age_Range'] = pd.cut(raw_data.Age, [0, 10, 20, 30, 40, 50, 60,70,80])\n",
    "    raw_data['Fare_Category'] = pd.cut(raw_data.Fare, bins=[0,7.90,14.45,31.28,120.0,513.0],include_lowest = True, labels=['Low','Mid','High_Mid','High','Upper_High'])\n",
    "    raw_data['isCabin']=raw_data.Cabin.apply(lambda x: 1 if x != 'NA' else 0)\n",
    "    np.seterr(divide = 'ignore')\n",
    "    raw_data['Log_Fare']=np.log10(raw_data.Fare).replace(-np.inf, 0)\n",
    "    #raw_train_data.iloc[np.where(raw_train_data.Log_Fare.values<np.finfo(np.float64).min)]\n",
    "    #raw_data['Fare_Category'] = pd.cut(raw_data['Fare'], bins=[0,7.90,14.45,31.28,120.0], labels=['Low','Mid','High_Mid','High'])\n",
    "    #raw_data['Fare_Category'] = pd.cut(raw_data['Fare'], [0,7.90,14.45,31.28,120.0,513.0],include_lowest = True)\n",
    "    #raw_data.Salutation.nunique()\n",
    "    #####################New features#####################\n",
    "    name_dict = {\"Capt\":       \"officer\",\n",
    "                 \"Col\":        \"officer\",\n",
    "                 \"Major\":      \"officer\",\n",
    "                 \"Dr\":         \"officer\",\n",
    "                 \"Rev\":        \"officer\",\n",
    "                 \"Jonkheer\":   \"snob\",\n",
    "                 \"Don\":        \"snob\",\n",
    "                 \"Sir\" :       \"snob\",\n",
    "                 \"the Countess\":\"snob\",\n",
    "                 \"Dona\":       \"snob\",\n",
    "                 \"Lady\" :      \"snob\",\n",
    "                 \"Mme\":        \"married\",\n",
    "                 \"Ms\":         \"married\",\n",
    "                 \"Mrs\" :       \"married\",\n",
    "                 \"Miss\" :      \"single\",\n",
    "                 \"Mlle\":       \"single\",\n",
    "                 \"Mr\" :        \"man\",\n",
    "                 \"Master\" :    \"boy\"\n",
    "                }\n",
    "    raw_data['Salutation_type'] = raw_data['Salutation'].map(name_dict)\n",
    "    \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data(raw_train_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cabin_only = raw_train_data[[\"Cabin\"]].copy()\n",
    "cabin_only[\"Cabin_Data\"] = cabin_only[\"Cabin\"].isnull().apply(lambda x: not x)\n",
    "cabin_only[\"Deck\"] = cabin_only[\"Cabin\"].str.slice(0,1)\n",
    "cabin_only[\"Room\"] = cabin_only[\"Cabin\"].str.slice(1,5).str.extract(\"([0-9]+)\", expand=False).astype(\"float\")\n",
    "cabin_only[cabin_only[\"Cabin_Data\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>Age_Range</th>\n",
       "      <th>Fare_Category</th>\n",
       "      <th>isCabin</th>\n",
       "      <th>Log_Fare</th>\n",
       "      <th>Salutation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(20, 30]</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860338</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>1.852988</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(20, 30]</td>\n",
       "      <td>Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>0.898999</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>1.725095</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905796</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NA</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(20, 30]</td>\n",
       "      <td>Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>0.927283</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(50, 60]</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>1.714853</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>LargeFamily</td>\n",
       "      <td>Master</td>\n",
       "      <td>(0, 10]</td>\n",
       "      <td>High_Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>1.323768</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(20, 30]</td>\n",
       "      <td>Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>1.046624</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NA</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(10, 20]</td>\n",
       "      <td>High_Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>1.478145</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(0, 10]</td>\n",
       "      <td>High_Mid</td>\n",
       "      <td>1</td>\n",
       "      <td>1.222716</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(50, 60]</td>\n",
       "      <td>High_Mid</td>\n",
       "      <td>1</td>\n",
       "      <td>1.424065</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(10, 20]</td>\n",
       "      <td>Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905796</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NA</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>LargeFamily</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>High_Mid</td>\n",
       "      <td>0</td>\n",
       "      <td>1.495197</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male  25.0      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "\n",
       "    Parch            Ticket     Fare Cabin Embarked  Family  Family_Size  \\\n",
       "0       0         A/5 21171   7.2500    NA        S       2  SmallFamily   \n",
       "1       0          PC 17599  71.2833   C85        C       2  SmallFamily   \n",
       "2       0  STON/O2. 3101282   7.9250    NA        S       1       Single   \n",
       "3       0            113803  53.1000  C123        S       2  SmallFamily   \n",
       "4       0            373450   8.0500    NA        S       1       Single   \n",
       "5       0            330877   8.4583    NA        Q       1       Single   \n",
       "6       0             17463  51.8625   E46        S       1       Single   \n",
       "7       1            349909  21.0750    NA        S       5  LargeFamily   \n",
       "8       2            347742  11.1333    NA        S       3  SmallFamily   \n",
       "9       0            237736  30.0708    NA        C       2  SmallFamily   \n",
       "10      1           PP 9549  16.7000    G6        S       3  SmallFamily   \n",
       "11      0            113783  26.5500  C103        S       1       Single   \n",
       "12      0         A/5. 2151   8.0500    NA        S       1       Single   \n",
       "13      5            347082  31.2750    NA        S       7  LargeFamily   \n",
       "\n",
       "   Salutation Age_Range Fare_Category  isCabin  Log_Fare Salutation_type  \n",
       "0          Mr  (20, 30]           Low        0  0.860338             man  \n",
       "1         Mrs  (30, 40]          High        1  1.852988         married  \n",
       "2        Miss  (20, 30]           Mid        0  0.898999          single  \n",
       "3         Mrs  (30, 40]          High        1  1.725095         married  \n",
       "4          Mr  (30, 40]           Mid        0  0.905796             man  \n",
       "5          Mr  (20, 30]           Mid        0  0.927283             man  \n",
       "6          Mr  (50, 60]          High        1  1.714853             man  \n",
       "7      Master   (0, 10]      High_Mid        0  1.323768             boy  \n",
       "8         Mrs  (20, 30]           Mid        0  1.046624         married  \n",
       "9         Mrs  (10, 20]      High_Mid        0  1.478145         married  \n",
       "10       Miss   (0, 10]      High_Mid        1  1.222716          single  \n",
       "11       Miss  (50, 60]      High_Mid        1  1.424065          single  \n",
       "12         Mr  (10, 20]           Mid        0  0.905796             man  \n",
       "13         Mr  (30, 40]      High_Mid        0  1.495197             man  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data.head(14)\n",
    "#display_all(df.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [data]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка пропусков\n",
    "NAs = pd.concat([raw_train_data.isnull().sum()], axis=1, keys=['data'])\n",
    "NAs[NAs.sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_train_data['Singleton']=raw_train_data['Family'].apply(lambda x: 1 if x == 1 else 0)\n",
    "#raw_train_data['SmallFamily']=raw_train_data['Family'].apply(lambda x: 1 if 2<=x <= 4 else 0)\n",
    "#raw_train_data['LargeFamily']=raw_train_data['Family'].apply(lambda x: 1 if 5<=x  else 0)\n",
    "#Удалим исходные, которые были базой\n",
    "#raw_train_data.drop(['SibSp','Parch','Age','Fare'], axis = 1, inplace = True)\n",
    "#raw_train_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = raw_train_data['Survived']\n",
    "train_data = raw_train_data.drop(['PassengerId', 'Survived'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data_columns = ['Name','Ticket','Cabin']\n",
    "categorical_data_columns = ['Pclass','Sex','Embarked','Salutation','Age_Range', 'Fare_Category','Family_Size','Salutation_type']\n",
    "numeric_data_columns = ['Age', 'SibSp', 'Parch', 'Fare','Family','isCabin','Log_Fare']\n",
    "#numeric_data_columns = ['Family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(train_data.columns))==set(string_data_columns+categorical_data_columns+numeric_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Оставшиеся колонки\n",
    "set(train_data.columns) - set(numeric_data_columns)-set(string_data_columns)-set(categorical_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data_indices = np.array([(column in categorical_data_columns) for column in train_data.columns], dtype = bool)\n",
    "numeric_data_indices = np.array([(column in numeric_data_columns) for column in train_data.columns], dtype = bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data\n",
       "Age      86\n",
       "Fare      1\n",
       "Cabin   327"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка пропусков\n",
    "NAs = pd.concat([raw_test_data.isnull().sum()], axis=1, keys=['data'])\n",
    "NAs[NAs.sum(axis=1) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [data]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка пропусков\n",
    "NAs = pd.concat([raw_test_data.isnull().sum()], axis=1, keys=['data'])\n",
    "NAs[NAs.sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = raw_test_data.drop(['PassengerId'], axis = 1)\n",
    "#Оставшиеся колонки\n",
    "set(test_data.columns) - set(numeric_data_columns)-set(string_data_columns)-set(categorical_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Все колонки (лин завис)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(numeric_data_indices,categorical_data_indices,classifier):\n",
    "    if  isinstance(classifier,ensemble.RandomForestClassifier) or isinstance(classifier,ensemble.GradientBoostingClassifier):\n",
    "        print('---------------RF/GB-------------')\n",
    "        estimator = pipeline.Pipeline(steps = [       \n",
    "            (\n",
    "                'feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                    #binary\n",
    "                    #('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "\n",
    "                    #numeric\n",
    "                    ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices],validate=False)),          \n",
    "                                ])),\n",
    "\n",
    "                    #categorical\n",
    "                    ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices],validate=False)),         \n",
    "                                ])),\n",
    "                ])\n",
    "            ),\n",
    "            ('model_fitting', classifier)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "         \n",
    "            \n",
    "    else:\n",
    "        estimator = pipeline.Pipeline(steps = [       \n",
    "            (\n",
    "                'feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                    #binary\n",
    "                    #('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "\n",
    "                    #numeric\n",
    "                    ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices],validate=False)),\n",
    "                        ('scaling', preprocessing.StandardScaler())            \n",
    "                                ])),\n",
    "\n",
    "                    #categorical\n",
    "                    ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices],validate=False)),\n",
    "                        ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown = 'ignore',sparse=False))            \n",
    "                                ])),\n",
    "                ])\n",
    "            ),\n",
    "            ('model_fitting', classifier)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(estimator, train_data.values, train_labels, scoring = 'accuracy', cv = 3)\n",
    "#estimator.fit(train_data.values, train_labels)\n",
    "#train_labels = raw_train_data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data.values, train_labels, test_size=0.5,shuffle=True, random_state=42)\n",
    "#stratify=train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((445, 18), (446, 18), (445,), (446,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### оценка алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кросс валидация тратегии\n",
    "cv_strategy_SKF = model_selection.StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "cv_strategy_KF =model_selection.KFold(n_splits=5, shuffle = True, random_state = 0)\n",
    "cv_strategy_ShS =model_selection.ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,random_state=0)\n",
    "cv_strategy_ShS =model_selection.StratifiedShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,random_state=0)\n",
    "cv_dict = {'SKF':cv_strategy_SKF,'KF':cv_strategy_KF,'ShS':cv_strategy_ShS,'ShS':cv_strategy_ShS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {'RiC':linear_model.RidgeClassifier(),'SVC':svm.SVC(gamma='auto'),'SGD':linear_model.SGDClassifier(),'LR':linear_model.LogisticRegression(solver='lbfgs'),\n",
    "                   'KNC':neighbors.KNeighborsClassifier(),#'DeTree':tree.DecisionTreeClassifier(),\n",
    "                   'RF':ensemble.RandomForestClassifier(n_estimators=10),'GB':ensemble.GradientBoostingClassifier(),\n",
    "                   'BG':ensemble.BaggingClassifier(),'NB':naive_bayes.GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Classifier***** RiC\n",
      "--cv-- SKF ---- StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- KF ---- KFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- ShS ---- StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.25,\n",
      "            train_size=0.5)\n",
      "***Classifier***** SVC\n",
      "--cv-- SKF ---- StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- KF ---- KFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- ShS ---- StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.25,\n",
      "            train_size=0.5)\n",
      "***Classifier***** SGD\n",
      "--cv-- SKF ---- StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- KF ---- KFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- ShS ---- StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.25,\n",
      "            train_size=0.5)\n",
      "***Classifier***** LR\n",
      "--cv-- SKF ---- StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- KF ---- KFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- ShS ---- StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.25,\n",
      "            train_size=0.5)\n",
      "***Classifier***** KNC\n",
      "--cv-- SKF ---- StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- KF ---- KFold(n_splits=5, random_state=0, shuffle=True)\n",
      "--cv-- ShS ---- StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.25,\n",
      "            train_size=0.5)\n",
      "***Classifier***** RF\n",
      "---------------RF/GB-------------\n",
      "--cv-- SKF ---- StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: could not convert string to float: 'male'\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: could not convert string to float: 'male'\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: could not convert string to float: 'female'\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: could not convert string to float: 'male'\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: could not convert string to float: 'male'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'male'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-7f99aeb80e4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mmin_res_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_scoring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mstd_res_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_scoring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mtest_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'male'"
     ]
    }
   ],
   "source": [
    "# кросс валидация оценка\n",
    "\n",
    "clf_res_list=[]\n",
    "cv_res_list=[]\n",
    "mean_res_list=[]\n",
    "max_res_list=[]\n",
    "min_res_list=[]\n",
    "std_res_list=[]\n",
    "test_acc=[]\n",
    "for k, v in classifier_dict.items():\n",
    "    #print(\"Code : {0}, Value : {1}\".format(k, v))\n",
    "    print('***Classifier*****',k)\n",
    "    clf=create_estimator(numeric_data_indices,categorical_data_indices,v)\n",
    "    for name,val in cv_dict.items():\n",
    "        clf_scoring = cross_val_score(clf, X_train, y_train, scoring = 'accuracy', cv = val)\n",
    "        print('--cv--',name,'----',val)\n",
    "        #print ('mean:{}, max:{}, min:{}, std:{}'.format(clf_scoring.mean(), clf_scoring.max(), clf_scoring.min(), clf_scoring.std()))\n",
    "        clf_res_list.append(k)\n",
    "        cv_res_list.append(name)\n",
    "        mean_res_list.append(clf_scoring.mean())\n",
    "        max_res_list.append(clf_scoring.max())\n",
    "        min_res_list.append(clf_scoring.min())\n",
    "        std_res_list.append(clf_scoring.std())\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        test_acc.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'clf':clf_res_list, 'cv':cv_res_list,'mean':mean_res_list,'max':max_res_list,'min':min_res_list,'std':std_res_list,'test_acc':test_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD\n",
    "#RidgeClassifier\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__alpha' : [1e-3, 1e-2, 1e-1, 1,1e1,1e2], #RC\n",
    "    #'model_fitting__kernel' : ['linear', 'poly', 'rbf', 'sigmoid'], #GB\n",
    "    #'model_fitting__class_weight' : [None,'balanced'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(numeric_data_indices,categorical_data_indices,linear_model.RidgeClassifier(fit_intercept=False))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#grid_cv.fit(train_data.values, train_labels)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grid_cv.best_estimator_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Коэфициенты модели\n",
    "#grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[0][1].fit_transform(X_train)[:2]\n",
    "#one_hot_cat_col=grid_cv.best_estimator_.steps[0][1].transformer_list[1][1][1].get_feature_names(categorical_data_columns)\n",
    "#grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[1][1].categories_\n",
    "all_column=numeric_data_columns+list(grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[1][1].get_feature_names())\n",
    "coef=grid_cv.best_estimator_.steps[1][1].coef_[0]\n",
    "sorted(zip(np.abs(coef),all_column),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "\n",
    "parameters_grid = {\n",
    "    #'model_fitting__C' : [0.01,0.1, 1, 10, 100,], \n",
    "    'model_fitting__C' : [0.8, 0.85, 0.9],\n",
    "    'model_fitting__kernel' : ['linear','rbf', 'sigmoid'], \n",
    "    'model_fitting__class_weight' : [None,'balanced'],\n",
    "    'model_fitting__decision_function_shape':['ovo', 'ovr'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(gamma='auto'))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8368263473053892\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__decision_function_shape': 'ovo', 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 18.8 s, sys: 39.8 ms, total: 18.9 s\n",
    "Wall time: 18.9 s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8368263473053892\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 1min 40s, sys: 2.51 ms, total: 1min 40s\n",
    "Wall time: 1min 40s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8327721661054994\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 40.1 s, sys: 0 ns, total: 40.1 s\n",
    "Wall time: 40.1 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoosting\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__n_estimators' : [3,4, 8, 16, 32, 64, 100], #GB\n",
    "    'model_fitting__max_depth' : [3,5,7], #GB\n",
    "    #'model_fitting__loss' : [\"deviance\",'exponential'],\n",
    "    'model_fitting__learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 1, 5),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 5),\n",
    "    'model_fitting__max_features':['auto',\"log2\",\"sqrt\",None],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(numeric_data_indices,categorical_data_indices,ensemble.GradientBoostingClassifier())\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8417508417508418\n",
    "{'model_fitting__learning_rate': 0.1, 'model_fitting__max_depth': 5, 'model_fitting__max_features': 'auto', 'model_fitting__n_estimators': 64}\n",
    "CPU times: user 1min 30s, sys: 0 ns, total: 1min 30s\n",
    "Wall time: 1min 30s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8451178451178452\n",
    "{'model_fitting__learning_rate': 0.25, 'model_fitting__max_depth': 5, 'model_fitting__min_samples_leaf': 0.1, 'model_fitting__min_samples_split': 0.325, 'model_fitting__n_estimators': 100}\n",
    "CPU times: user 2min 22s, sys: 320 ms, total: 2min 22s\n",
    "Wall time: 2min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=grid_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__C' : [0.001,0.01,0.1,1,10,100], #GB\n",
    "    #'model_fitting__penalty' : ['l2','l1','none'],\n",
    "    'model_fitting__solver' : ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(numeric_data_indices,categorical_data_indices,linear_model.LogisticRegression(max_iter=1000))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8260381593714927\n",
    "{'model_fitting__C': 10}\n",
    "CPU times: user 928 ms, sys: 16 ms, total: 944 ms\n",
    "Wall time: 478 ms\n",
    "solver='lbfgs',penalty = 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__n_estimators' : [1, 2, 4, 8, 16, 32, 64, 100, 200,500], #GB\n",
    "    #'model_fitting__max_depth' : np.linspace(1, 32, 32, endpoint=True), #GB\n",
    "    #'model_fitting__loss' : [\"deviance\",'exponential'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    'model_fitting__min_samples_split': [2,5,7,10],\n",
    "    'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\",'auto'],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "    #'model_fitting__class_weight' : ['balanced',None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(numeric_data_indices,categorical_data_indices,ensemble.RandomForestClassifier(class_weight='balanced'))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7957351290684624\n",
    "{'model_fitting__n_estimators': 64, 'model_fitting__min_samples_split': 0.2, 'model_fitting__min_samples_leaf': 0.1, 'model_fitting__max_features': 'sqrt', 'model_fitting__max_depth': 2.0}\n",
    "CPU times: user 15.4 s, sys: 136 ms, total: 15.6 s\n",
    "Wall time: 15.6 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение финального классификатора ALL_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__gamma' : ['auto',0.0001,0.001,0.01,0.1,1,10], \n",
    "    'model_fitting__C' : [0.01,0.1, 1, 10],\n",
    "    'model_fitting__kernel' : ['linear','rbf', 'sigmoid'], #GB\n",
    "    'model_fitting__class_weight' : [None,'balanced'],\n",
    "    'model_fitting__decision_function_shape':['ovo', 'ovr'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(gamma='auto'))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(train_data.values, train_labels)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8305274971941639\n",
    "{'model_fitting__kernel': 'rbf', 'model_fitting__gamma': 'auto', 'model_fitting__decision_function_shape': 'ovo', 'model_fitting__class_weight': None, 'model_fitting__C': 1}\n",
    "CPU times: user 5.11 s, sys: 0 ns, total: 5.11 s\n",
    "Wall time: 5.11 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### формирование файла Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grid_cv.predict(test_data.values)\n",
    "submission = pd.DataFrame({'PassengerId':raw_test_data.PassengerId,'Survived':result})\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "print(submission.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'titanic13_SVC.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразование категориальных признаков в отдельном df\n",
    "#dummy_data=pd.get_dummies(data=raw_test_data, columns=categorical_data_columns)\n",
    "#dummy_index=dummy_data.columns.str.contains('|'.join(categorical_data_columns))\n",
    "#dummy_data=dummy_data.loc[:,dummy_index]\n",
    "#Числовые данные в отдельном df\n",
    "#numeric_data=raw_test_data[numeric_data_columns]\n",
    "#создаем стандартный scaler\n",
    "#scaler = StandardScaler()\n",
    "#scaled_test_data=scaler.transform(numeric_data)\n",
    "#scaled_test_data = scaler.transform(test_data)\n",
    "#all_test_data=np.hstack((scaled_test_data,dummy_data.values))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# найти все признаки, в которых первое значение - строка\n",
    "def find_cat(data):\n",
    "    for name in data.columns:\n",
    "        s = ''\n",
    "        s += name\n",
    "        if (type(data[name][0]) == str):\n",
    "            s += ' строка,'\n",
    "        if (data[name].nunique()<=3):\n",
    "            s += ' мало уникальных'\n",
    "        if (s!=name):\n",
    "            print (s)\n",
    "            \n",
    "find_cat(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(train_data.values, train_labels.values, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st.shape,y_train_st.shape,y_train_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.RidgeClassifier(alpha=10.0)\n",
    "#svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')\n",
    "#\n",
    "clfs = [create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.LogisticRegression(solver='liblinear',class_weight=None,tol=1e-05, penalty='l2')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.RidgeClassifier(alpha=10.0)),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,ensemble.GradientBoostingClassifier(learning_rate= 0.1, max_depth= 3, max_features='auto', n_estimators= 32))\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train = np.zeros((X_train_st.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    for i, (train_, test_) in enumerate(kf.split(X_train_st, y_train_st)):\n",
    "        print (\"Fold\", i)\n",
    "        X_tr = X_train_st[train_]\n",
    "        y_tr = y_train_st[train_]\n",
    "        X_te = X_train_st[test_]\n",
    "        y_te = y_train_st[test_]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        print('------------------------',type(clf[1]))\n",
    "        if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "            print('----------SVM/RidgeCl-------')\n",
    "            y_submission = clf.predict(X_te)\n",
    "        else:\n",
    "            print('----------Other-------')\n",
    "            y_submission = clf.predict_proba(X_te)[:, 1]\n",
    "        dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(clf[1],svm.SVC),\n",
    "type(clf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = linear_model.RidgeClassifier(class_weight=None,tol=1e-05, random_state=11)\n",
    "ls = cross_val_score(clf2, dataset_blend_train, y_train_st, cv=5, scoring='accuracy')\n",
    "print(ls)\n",
    "np.mean(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.fit(dataset_blend_train, y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf2.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест для стекинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "X_meta = np.zeros((X_test_st.shape[0],len(clfs)))\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    #for i, (train_, test_) in enumerate(kf.split(train_data, train_labels)):\n",
    "    #    print (\"Fold\", i)\n",
    "    #    X_tr = train_data.values[train_]\n",
    "    #    y_tr = train_labels[train_]\n",
    "    #    X_te = train_data.values[test_]\n",
    "    #    y_te = train_labels[test_]\n",
    "    #    clf_pipeline=create_estimator(numeric_data_indices,categorical_data_indices,clf)\n",
    "    #    clf_pipeline.fit(X_tr, y_tr)\n",
    "    print('------------------------',type(clf[1]))\n",
    "    if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "        print('----------SVM/RidgeCl-------')\n",
    "        #y_submission = clf_.predict(X_te)\n",
    "        X_meta[:, j] = clf.predict(X_test_st)\n",
    "    else:\n",
    "        print('----------Other-------')\n",
    "        #y_submission = clf_pipeline.predict_proba(X_te)[:, 1]\n",
    "        X_meta[:, j] = clf.predict_proba(X_test_st)[:, 1]\n",
    "    #dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape,X_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_meta=clf2.predict(X_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_st, pred_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стекинг для ответа kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.RidgeClassifier(alpha=10.0)\n",
    "#svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')\n",
    "#\n",
    "clfs = [create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.LogisticRegression(solver='liblinear',class_weight=None,tol=1e-05, penalty='l2')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.RidgeClassifier(alpha=10.0)),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,ensemble.GradientBoostingClassifier(learning_rate= 0.1, max_depth= 3, max_features='auto', n_estimators= 32))\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st_kaggle=train_data.values\n",
    "y_train_st_kaggle=train_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train = np.zeros((X_train_st_kaggle.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    for i, (train_, test_) in enumerate(kf.split(X_train_st_kaggle, y_train_st_kaggle)):\n",
    "        print (\"Fold\", i)\n",
    "        X_tr = X_train_st_kaggle[train_]\n",
    "        y_tr = y_train_st_kaggle[train_]\n",
    "        X_te = X_train_st_kaggle[test_]\n",
    "        y_te = y_train_st_kaggle[test_]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        print('------------------------',type(clf[1]))\n",
    "        if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "            print('----------SVM/RidgeCl-------')\n",
    "            y_submission = clf.predict(X_te)\n",
    "        else:\n",
    "            print('----------Other-------')\n",
    "            y_submission = clf.predict_proba(X_te)[:, 1]\n",
    "        dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_kaggle = linear_model.RidgeClassifier(class_weight=None,tol=1e-05, random_state=11)\n",
    "clf_meta_kaggle.fit(dataset_blend_train, y_train_st_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг test для kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st_kaggle=test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "X_meta = np.zeros((X_test_st_kaggle.shape[0],len(clfs)))\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    #for i, (train_, test_) in enumerate(kf.split(train_data, train_labels)):\n",
    "    #    print (\"Fold\", i)\n",
    "    #    X_tr = train_data.values[train_]\n",
    "    #    y_tr = train_labels[train_]\n",
    "    #    X_te = train_data.values[test_]\n",
    "    #    y_te = train_labels[test_]\n",
    "    #    clf_pipeline=create_estimator(numeric_data_indices,categorical_data_indices,clf)\n",
    "    #    clf_pipeline.fit(X_tr, y_tr)\n",
    "    print('------------------------',type(clf[1]))\n",
    "    if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "        print('----------SVM/RidgeCl-------')\n",
    "        #y_submission = clf_.predict(X_te)\n",
    "        X_meta[:, j] = clf.predict(X_test_st_kaggle)\n",
    "    else:\n",
    "        print('----------Other-------')\n",
    "        #y_submission = clf_pipeline.predict_proba(X_te)[:, 1]\n",
    "        X_meta[:, j] = clf.predict_proba(X_test_st_kaggle)[:, 1]\n",
    "    #dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=clf_meta_kaggle.predict(X_meta)\n",
    "submission = pd.DataFrame({'PassengerId':raw_test_data.PassengerId,'Survived':result})\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'titanic16_stack.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
