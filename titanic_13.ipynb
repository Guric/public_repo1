{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection , linear_model, metrics, pipeline,tree, preprocessing,neighbors,ensemble,svm,naive_bayes\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,train_test_split,RandomizedSearchCV,cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "\n",
    "#from sklearn import model_selection import grid_search\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from itertools import *\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data = pd.read_csv('./data/train.csv')\n",
    "original_test_data = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data,mode): \n",
    "    \n",
    "    #Обработка пропусков\n",
    "    #Заполняем медианой\n",
    "    #raw_data.Age = raw_data.Age.fillna(raw_data.Age.median())\n",
    "    #Заполняем медианой c группировкой\n",
    "    raw_data=data.copy()\n",
    "    grp = raw_data.groupby(['Sex', 'Pclass'])  \n",
    "    raw_data.Age = grp.Age.apply(lambda x: x.fillna(x.median()))\n",
    "    #Заполняем модой\n",
    "    #raw_data.Embarked = raw_data.Embarked.fillna(raw_data.Embarked.value_counts().idxmax())\n",
    "    raw_data.Embarked.fillna(raw_data.Embarked.mode()[0], inplace = True)\n",
    "    raw_data.Fare.fillna(raw_data.Fare.mode()[0],inplace = True)\n",
    "    #Заполняем 'N'\n",
    "    raw_data.Cabin = raw_data.Cabin.fillna('NA')\n",
    "\n",
    "    \n",
    "    if mode=='new_features':\n",
    "        print('--new_features mode--')\n",
    "        #raw_data.Embarked.value_counts()\n",
    "        #добавим новые признаки\n",
    "        raw_data['Family'] = raw_data.Parch + raw_data.SibSp+1\n",
    "        raw_data['Family_Size'] = pd.cut(raw_data.Family, [0,1.5,4.5,15],labels=['Single','SmallFamily','LargeFamily'])\n",
    "        #raw_data['Is_Alone'] = (raw_data.Family == 0).astype(int)\n",
    "        raw_data['Salutation'] = raw_data.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip()) \n",
    "        raw_data['Age_Range'] = pd.cut(raw_data.Age, [0, 10, 20, 30, 40, 50, 60,70,80])\n",
    "        raw_data['Fare_Category'] = pd.cut(raw_data.Fare, bins=[0,7.90,14.45,31.28,120.0,513.0],include_lowest = True, labels=['Low','Mid','High_Mid','High','Upper_High'])\n",
    "        raw_data['isCabin']=raw_data.Cabin.apply(lambda x: 1 if x != 'NA' else 0)\n",
    "        np.seterr(divide = 'ignore')\n",
    "        raw_data['Log_Fare']=np.log10(raw_data.Fare).replace(-np.inf, 0)\n",
    "        #raw_train_data.iloc[np.where(raw_train_data.Log_Fare.values<np.finfo(np.float64).min)]\n",
    "        #raw_data['Fare_Category'] = pd.cut(raw_data['Fare'], bins=[0,7.90,14.45,31.28,120.0], labels=['Low','Mid','High_Mid','High'])\n",
    "        #raw_data['Fare_Category'] = pd.cut(raw_data['Fare'], [0,7.90,14.45,31.28,120.0,513.0],include_lowest = True)\n",
    "        #raw_data.Salutation.nunique()\n",
    "        #####################New features#####################\n",
    "        name_dict = {\"Capt\":       \"officer\",\n",
    "                     \"Col\":        \"officer\",\n",
    "                     \"Major\":      \"officer\",\n",
    "                     \"Dr\":         \"officer\",\n",
    "                     \"Rev\":        \"officer\",\n",
    "                     \"Jonkheer\":   \"snob\",\n",
    "                     \"Don\":        \"snob\",\n",
    "                     \"Sir\" :       \"snob\",\n",
    "                     \"the Countess\":\"snob\",\n",
    "                     \"Dona\":       \"snob\",\n",
    "                     \"Lady\" :      \"snob\",\n",
    "                     \"Mme\":        \"married\",\n",
    "                     \"Ms\":         \"married\",\n",
    "                     \"Mrs\" :       \"married\",\n",
    "                     \"Miss\" :      \"single\",\n",
    "                     \"Mlle\":       \"single\",\n",
    "                     \"Mr\" :        \"man\",\n",
    "                     \"Master\" :    \"boy\"\n",
    "                    }\n",
    "        raw_data['Salutation_type'] = raw_data['Salutation'].map(name_dict)\n",
    "        \n",
    "    else:\n",
    "        print('--Original mode--')\n",
    "        pass\n",
    "        \n",
    "    return raw_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(numeric_data_indices,categorical_data_indices,classifier):\n",
    "    estimator = pipeline.Pipeline(steps = [       \n",
    "        (\n",
    "            'feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                #binary\n",
    "                #('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "                        \n",
    "                #numeric\n",
    "                ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                    ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices],validate=False)),\n",
    "                    ('scaling', preprocessing.StandardScaler())            \n",
    "                            ])),\n",
    "        \n",
    "                #categorical\n",
    "                ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "                    ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices],validate=False)),\n",
    "                    ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown = 'ignore',sparse=False))            \n",
    "                            ])),\n",
    "            ])\n",
    "        ),\n",
    "        ('model_fitting', classifier)\n",
    "        ]\n",
    "    )\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--new_features mode--\n"
     ]
    }
   ],
   "source": [
    "#Подготовка с отбором признаков\n",
    "\n",
    "#exclude_col = ['Name', 'Embarked', 'Cabin', 'isCabin','Salutation', 'Sex', 'Family']\n",
    "#['Name', 'Embarked', 'Cabin', 'isCabin'] ['Salutation', 'Sex', 'Family']\n",
    "#prepare_data(raw_train_data,[])\n",
    "\n",
    "\n",
    "\n",
    "train_data=prepare_data(original_train_data,'new_features')\n",
    "\n",
    "train_labels = train_data['Survived']\n",
    "train_data.drop(['PassengerId', 'Survived'], axis = 1,inplace=True)\n",
    "all_column=train_data.columns\n",
    "#Описание колонок и индексов для FeatureUnion\n",
    "string_data_columns = ['Name','Ticket','Cabin']\n",
    "categorical_data_columns = ['Pclass','Sex','Embarked','Salutation','Age_Range', 'Fare_Category','Family_Size','Salutation_type']\n",
    "numeric_data_columns = ['Age', 'SibSp', 'Parch', 'Fare','Family','isCabin','Log_Fare']\n",
    "categorical_data_indices = np.array([(column in categorical_data_columns) for column in train_data.columns], dtype = bool)\n",
    "numeric_data_indices = np.array([(column in numeric_data_columns) for column in train_data.columns], dtype = bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.loc[:,categorical_data_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, False, False,  True,  True,  True, False,  True, False,\n",
       "        False,  True, False, False, False, False,  True,  True, False]),\n",
       " array([ True, False,  True, False, False, False, False, False, False,\n",
       "         True, False,  True,  True,  True,  True, False, False,  True]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data_indices,categorical_data_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper methods(Включение исключения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_estimator(numeric_data_indices,categorical_data_indices,linear_model.LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_data.values, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = linear_model.LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model2.fit(train_data.loc[:,numeric_data_columns].values, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(model,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Braund, Mr. Owen Harris'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a2366a2d9a58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \"\"\"\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         X, y = check_X_y(X, y, \"csc\", ensure_min_features=2,\n\u001b[1;32m--> 159\u001b[1;33m                          force_all_finite=not tags.get('allow_nan', True))\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;31m# Initialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\users\\guric\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Braund, Mr. Owen Harris'"
     ]
    }
   ],
   "source": [
    "fit = rfe.fit(train_data.values, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num Features: %d',fit.n_features_)\n",
    "print('Selected Features:', fit.support_)\n",
    "print('Feature Ranking:', fit.ranking_)\n",
    "print('Feature Coef:', model2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.loc[:,numeric_data_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(kernel=\"linear\"))\n",
    "svc.fit(train_data.values, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc = svm.SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=model_selection.StratifiedKFold(2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(train_data.values, train_labels)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перебор подмножеств признаков n<=5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier_dict = {'RiC':linear_model.RidgeClassifier(),'SVC':svm.SVC(gamma='auto'),'SGD':linear_model.SGDClassifier(),'LR':linear_model.LogisticRegression(solver='lbfgs'),\n",
    "                   'KNC':neighbors.KNeighborsClassifier(),'DeTree':tree.DecisionTreeClassifier(),\n",
    "                   'RF':ensemble.RandomForestClassifier(n_estimators=10),'GB':ensemble.GradientBoostingClassifier(),\n",
    "                   'BG':ensemble.BaggingClassifier(),'NB':naive_bayes.GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier_dict = {'RiC':linear_model.RidgeClassifier(),'SVC':svm.SVC(gamma='auto') ,'RF':ensemble.RandomForestClassifier(n_estimators=10),'GB':ensemble.GradientBoostingClassifier(),'KNC':neighbors.KNeighborsClassifier(),'DeTree':tree.DecisionTreeClassifier()}\n",
    "classifier_dict = {'GB':ensemble.GradientBoostingClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сочетание без повторений\n",
    "combinations_features_1=[[x] for x in all_column]\n",
    "print('len combinations_features_1:',len(combinations_features_1))\n",
    "combinations_features_2=[list(set().union(*x)) for x in combinations(combinations_features_1, 2)]\n",
    "print('len combinations_features_2:',len(combinations_features_2))\n",
    "combinations_features_3=[list(set().union(*x)) for x in combinations(combinations_features_1, 3)]\n",
    "print('len combinations_features_3:',len(combinations_features_3))\n",
    "combinations_features_4=[list(set().union(*x)) for x in combinations(combinations_features_1, 4)]\n",
    "print('len combinations_features_4:',len(combinations_features_4))\n",
    "#combinations_features_5=[list(set().union(*x)) for x in combinations(combinations_features_1, 5)]\n",
    "#print('len combinations_features_5:',len(combinations_features_5))\n",
    "combinations_features_all=[[]]+combinations_features_1+combinations_features_2+\\\n",
    "combinations_features_3+combinations_features_4#+combinations_features_5\n",
    "print('len combinations_features_all:',len(combinations_features_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Перебор изъятия признаков\n",
    "\n",
    "\n",
    "exclude_col_list=[]\n",
    "clf_res_list=[]\n",
    "#cv_res_list=[]\n",
    "mean_res_list=[]\n",
    "max_res_list=[]\n",
    "min_res_list=[]\n",
    "std_res_list=[]\n",
    "#test_acc=[]\n",
    "#for exclude_col in all_column:\n",
    "for exclude_col in combinations_features_all:\n",
    "    #exclude_col=list(set().union(*exclude_col_tup))\n",
    "    #print(exclude_col)\n",
    "    \n",
    "    current_train_data=train_data.copy()\n",
    "    current_train_data.drop(exclude_col, axis = 1,inplace=True)\n",
    "    current_categorical_data_indices = np.array([(column in categorical_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "    current_numeric_data_indices = np.array([(column in numeric_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "\n",
    "    for k, v in classifier_dict.items():\n",
    "        #print(\"Code : {0}, Value : {1}\".format(k, v))\n",
    "        #print('***Classifier*****',k)\n",
    "        clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,v)\n",
    "        clf_scoring = cross_val_score(clf, current_train_data.values, train_labels, scoring = 'accuracy', cv = 3)\n",
    "            #print ('mean:{}, max:{}, min:{}, std:{}'.format(clf_scoring.mean(), clf_scoring.max(), clf_scoring.min(), clf_scoring.std()))\n",
    "        exclude_col_list.append(exclude_col)   \n",
    "        clf_res_list.append(k)\n",
    "        #cv_res_list.append(name)\n",
    "        mean_res_list.append(clf_scoring.mean())\n",
    "        max_res_list.append(clf_scoring.max())\n",
    "        min_res_list.append(clf_scoring.min())\n",
    "        std_res_list.append(clf_scoring.std())\n",
    "        #clf.fit(X_train, y_train)\n",
    "        #y_pred=clf.predict(X_test)\n",
    "        #test_acc.append(accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df=pd.DataFrame({'ex_col':exclude_col_list,'clf':clf_res_list,'mean':mean_res_list,'max':max_res_list,'min':min_res_list,'std':std_res_list})\n",
    "select_f_df.sort_values(by=['mean'],ascending=False)#.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df.sort_values(by=['mean'],ascending=False)#.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select_f_df.to_csv('select_f_df_origin')\n",
    "select_f_df.nlargest(10, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df_max_10_mean=select_f_df[select_f_df.clf=='GB'].nlargest(10, 'mean').copy()\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='KNC'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='DeTree'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='DeTree'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='RF'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='SVC'].nlargest(10, 'mean'))\n",
    "select_f_df_max_10_mean=select_f_df_max_10_mean.append(select_f_df[select_f_df.clf=='RiC'].nlargest(10, 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df[select_f_df.clf=='SVC'].nlargest(10, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df_max_10_mean.groupby(['clf']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_f_df_max_10_mean.sort_values(by=['mean'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подготовка с отбором признаков\n",
    "exclude_col=['Age', 'Family_Size', 'Salutation', 'Fare_Category']\n",
    "#exclude_col = ['Name', 'Embarked', 'Cabin', 'isCabin','Salutation', 'Sex', 'Family']\n",
    "#['Name', 'Embarked', 'Cabin', 'isCabin'] ['Salutation', 'Sex', 'Family']\n",
    "#prepare_data(raw_train_data,[])\n",
    "\n",
    "#current_train_data=original_train_data.copy()\n",
    "#prepare_data(current_train_data,exclude_col)\n",
    "#train_labels = raw_train_data['Survived']\n",
    "#current_train_data = current_train_data.drop(['PassengerId', 'Survived'], axis = 1)\n",
    "#print(current_train_data.columns)\n",
    "#current_categorical_data_indices = np.array([(column in categorical_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "#current_numeric_data_indices = np.array([(column in numeric_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "#clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,v)\n",
    "#clf_scoring = cross_val_score(clf, current_train_data.values, train_labels, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "current_train_data=train_data.copy()\n",
    "current_train_data.drop(exclude_col, axis = 1,inplace=True)\n",
    "current_categorical_data_indices = np.array([(column in categorical_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "current_numeric_data_indices = np.array([(column in numeric_data_columns) for column in current_train_data.columns], dtype = bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(current_train_data.values, train_labels, test_size=0.33,shuffle=True, random_state=42)\n",
    "#stratify=train_labels\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=prepare_data(original_test_data,'new_features')\n",
    "#current_train_data=original_train_data.copy()\n",
    "#prepare_data(current_train_data,'',exclude_col)\n",
    "#train_labels = train_data['Survived']\n",
    "test_data.drop(['PassengerId']+exclude_col, axis = 1,inplace=True)\n",
    "all_column_test=test_data.columns\n",
    "#Описание колонок и индексов для FeatureUnion\n",
    "#Колонки\n",
    "#Проверка пропусков\n",
    "NAs = pd.concat([test_data.isnull().sum()], axis=1, keys=['data'])\n",
    "print('Проверка пропусков',NAs[NAs.sum(axis=1) > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### оценка алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кросс валидация cтратегии\n",
    "cv_strategy_SKF = model_selection.StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "cv_strategy_KF =model_selection.KFold(n_splits=5, shuffle = True, random_state = 0)\n",
    "cv_strategy_ShS =model_selection.ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,random_state=0)\n",
    "cv_strategy_ShS =model_selection.StratifiedShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,random_state=0)\n",
    "cv_dict = {'SKF':cv_strategy_SKF,'KF':cv_strategy_KF,'ShS':cv_strategy_ShS,'ShS':cv_strategy_ShS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {'RiC':linear_model.RidgeClassifier(),'SVC':svm.SVC(gamma='auto'),'SGD':linear_model.SGDClassifier(),'LR':linear_model.LogisticRegression(solver='lbfgs'),\n",
    "                   'KNC':neighbors.KNeighborsClassifier(),'DeTree':tree.DecisionTreeClassifier(),\n",
    "                   'RF':ensemble.RandomForestClassifier(n_estimators=10),'GB':ensemble.GradientBoostingClassifier(),\n",
    "                   'BG':ensemble.BaggingClassifier(),'NB':naive_bayes.GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# кросс валидация оценка\n",
    "\n",
    "clf_res_list=[]\n",
    "cv_res_list=[]\n",
    "mean_res_list=[]\n",
    "max_res_list=[]\n",
    "min_res_list=[]\n",
    "std_res_list=[]\n",
    "test_acc=[]\n",
    "for k, v in classifier_dict.items():\n",
    "    #print(\"Code : {0}, Value : {1}\".format(k, v))\n",
    "    print('***Classifier*****',k)\n",
    "    clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,v)\n",
    "    for name,val in cv_dict.items():\n",
    "        clf_scoring = cross_val_score(clf, X_train, y_train, scoring = 'accuracy', cv = val)\n",
    "        print('--cv--',name,'----',val)\n",
    "        #print ('mean:{}, max:{}, min:{}, std:{}'.format(clf_scoring.mean(), clf_scoring.max(), clf_scoring.min(), clf_scoring.std()))\n",
    "        clf_res_list.append(k)\n",
    "        cv_res_list.append(name)\n",
    "        mean_res_list.append(clf_scoring.mean())\n",
    "        max_res_list.append(clf_scoring.max())\n",
    "        min_res_list.append(clf_scoring.min())\n",
    "        std_res_list.append(clf_scoring.std())\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        test_acc.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_table=pd.DataFrame({'clf':clf_res_list, 'cv':cv_res_list,'mean':mean_res_list,'max':max_res_list,'min':min_res_list,'std':std_res_list,'test_acc':test_acc})\n",
    "res_table.sort_values(by=['test_acc'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD\n",
    "#RidgeClassifier\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__alpha' : [1e-3, 1e-2, 1e-1, 1,1e1,1e2], #RC\n",
    "    #'model_fitting__kernel' : ['linear', 'poly', 'rbf', 'sigmoid'], #GB\n",
    "    #'model_fitting__class_weight' : [None,'balanced'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,linear_model.RidgeClassifier(fit_intercept=False))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#grid_cv.fit(train_data.values, train_labels)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grid_cv.best_estimator_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Коэфициенты модели\n",
    "#grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[0][1].fit_transform(X_train)[:2]\n",
    "#one_hot_cat_col=grid_cv.best_estimator_.steps[0][1].transformer_list[1][1][1].get_feature_names(categorical_data_columns)\n",
    "#grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[1][1].categories_\n",
    "all_column=numeric_data_columns+list(grid_cv.best_estimator_.steps[0][1].transformer_list[1][1].steps[1][1].get_feature_names())\n",
    "coef=grid_cv.best_estimator_.steps[1][1].coef_[0]\n",
    "sorted(zip(np.abs(coef),all_column),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__C' : [0.01,0.1, 1, 10, 100,], \n",
    "    #'model_fitting__C' : [0.8, 0.85, 0.9],\n",
    "    'model_fitting__kernel' : ['linear','rbf', 'sigmoid'], \n",
    "    'model_fitting__class_weight' : [None,'balanced'],\n",
    "    'model_fitting__decision_function_shape':['ovo', 'ovr'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,svm.SVC(gamma='auto'))\n",
    "cv = model_selection.KFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv,iid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=40,iid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8359550561797753\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__decision_function_shape': 'ovo', 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 7.8 s, sys: 0 ns, total: 7.8 s\n",
    "Wall time: 7.8 s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8368263473053892\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__decision_function_shape': 'ovo', 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 18.8 s, sys: 39.8 ms, total: 18.9 s\n",
    "Wall time: 18.9 s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8368263473053892\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 1min 40s, sys: 2.51 ms, total: 1min 40s\n",
    "Wall time: 1min 40s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8327721661054994\n",
    "{'model_fitting__C': 1, 'model_fitting__class_weight': None, 'model_fitting__kernel': 'rbf'}\n",
    "CPU times: user 40.1 s, sys: 0 ns, total: 40.1 s\n",
    "Wall time: 40.1 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoosting\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__n_estimators' : [3,4, 8, 16, 32, 64, 100], #GB\n",
    "    'model_fitting__max_depth' : [3,5,7], #GB\n",
    "    #'model_fitting__loss' : [\"deviance\",'exponential'],\n",
    "    'model_fitting__learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 1, 5),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 5),\n",
    "    'model_fitting__max_features':['auto',\"log2\",\"sqrt\",None],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,ensemble.GradientBoostingClassifier())\n",
    "cv = model_selection.KFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv,iid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.851685393258427\n",
    "{'model_fitting__learning_rate': 0.01, 'model_fitting__max_depth': 5, 'model_fitting__max_features': 'log2', 'model_fitting__n_estimators': 100}\n",
    "CPU times: user 1min 9s, sys: 7.85 ms, total: 1min 9s\n",
    "Wall time: 1min 9s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8471910112359551\n",
    "{'model_fitting__n_estimators': 100, 'model_fitting__max_features': 'log2', 'model_fitting__max_depth': 5, 'model_fitting__learning_rate': 0.01}\n",
    "CPU times: user 14.5 s, sys: 3.94 ms, total: 14.5 s\n",
    "Wall time: 14.6 s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8417508417508418\n",
    "{'model_fitting__learning_rate': 0.1, 'model_fitting__max_depth': 5, 'model_fitting__max_features': 'auto', 'model_fitting__n_estimators': 64}\n",
    "CPU times: user 1min 30s, sys: 0 ns, total: 1min 30s\n",
    "Wall time: 1min 30s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8451178451178452\n",
    "{'model_fitting__learning_rate': 0.25, 'model_fitting__max_depth': 5, 'model_fitting__min_samples_leaf': 0.1, 'model_fitting__min_samples_split': 0.325, 'model_fitting__n_estimators': 100}\n",
    "CPU times: user 2min 22s, sys: 320 ms, total: 2min 22s\n",
    "Wall time: 2min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=grid_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__C' : [0.001,0.01,0.1,1,10,100], #GB\n",
    "    #'model_fitting__penalty' : ['l2','l1','none'],\n",
    "    'model_fitting__solver' : ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,linear_model.LogisticRegression(max_iter=1000))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8260381593714927\n",
    "{'model_fitting__C': 10}\n",
    "CPU times: user 928 ms, sys: 16 ms, total: 944 ms\n",
    "Wall time: 478 ms\n",
    "solver='lbfgs',penalty = 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор пареметров для RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__n_estimators' : [1, 2, 4, 8, 16, 32, 64, 100, 200,500], #GB\n",
    "    #'model_fitting__max_depth' : np.linspace(1, 32, 32, endpoint=True), #GB\n",
    "    #'model_fitting__loss' : [\"deviance\",'exponential'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    'model_fitting__min_samples_split': [2,5,7,10],\n",
    "    'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\",'auto'],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "    #'model_fitting__class_weight' : ['balanced',None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,ensemble.RandomForestClassifier(class_weight='balanced'))\n",
    "cv = model_selection.StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7957351290684624\n",
    "{'model_fitting__n_estimators': 64, 'model_fitting__min_samples_split': 0.2, 'model_fitting__min_samples_leaf': 0.1, 'model_fitting__max_features': 'sqrt', 'model_fitting__max_depth': 2.0}\n",
    "CPU times: user 15.4 s, sys: 136 ms, total: 15.6 s\n",
    "Wall time: 15.6 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение финального классификатора ALL_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "\n",
    "parameters_grid = {\n",
    "    'model_fitting__C' : [0.01,0.1, 1, 10, 100,], \n",
    "    #'model_fitting__C' : [0.8, 0.85, 0.9],\n",
    "    'model_fitting__kernel' : ['linear','rbf', 'sigmoid'], \n",
    "    'model_fitting__class_weight' : [None,'balanced'],\n",
    "    'model_fitting__decision_function_shape':['ovo', 'ovr'],\n",
    "    #'model_fitting__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #'model_fitting__learning_rate': [0.2],\n",
    "    #'model_fitting__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    #'model_fitting__max_features':[\"log2\",\"sqrt\"],\n",
    "    #'model_fitting__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "    #\"model_fitting__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    #'model_fitting__subsample':[0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=create_estimator(current_numeric_data_indices,current_categorical_data_indices,svm.SVC(gamma='auto'))\n",
    "cv = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(clf, parameters_grid, cv = cv,iid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = RandomizedSearchCV(clf, parameters_grid, cv = cv,iid=False,n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv.fit(current_train_data.values, train_labels)\n",
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8305274971941639\n",
    "{'model_fitting__kernel': 'rbf', 'model_fitting__gamma': 'auto', 'model_fitting__decision_function_shape': 'ovo', 'model_fitting__class_weight': None, 'model_fitting__C': 1}\n",
    "CPU times: user 5.11 s, sys: 0 ns, total: 5.11 s\n",
    "Wall time: 5.11 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### формирование файла Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grid_cv.predict(test_data.values)\n",
    "submission = pd.DataFrame({'PassengerId':original_test_data.PassengerId,'Survived':result})\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "print(submission.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'titanic18_sf_5_SVC.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразование категориальных признаков в отдельном df\n",
    "#dummy_data=pd.get_dummies(data=raw_test_data, columns=categorical_data_columns)\n",
    "#dummy_index=dummy_data.columns.str.contains('|'.join(categorical_data_columns))\n",
    "#dummy_data=dummy_data.loc[:,dummy_index]\n",
    "#Числовые данные в отдельном df\n",
    "#numeric_data=raw_test_data[numeric_data_columns]\n",
    "#создаем стандартный scaler\n",
    "#scaler = StandardScaler()\n",
    "#scaled_test_data=scaler.transform(numeric_data)\n",
    "#scaled_test_data = scaler.transform(test_data)\n",
    "#all_test_data=np.hstack((scaled_test_data,dummy_data.values))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# найти все признаки, в которых первое значение - строка\n",
    "def find_cat(data):\n",
    "    for name in data.columns:\n",
    "        s = ''\n",
    "        s += name\n",
    "        if (type(data[name][0]) == str):\n",
    "            s += ' строка,'\n",
    "        if (data[name].nunique()<=3):\n",
    "            s += ' мало уникальных'\n",
    "        if (s!=name):\n",
    "            print (s)\n",
    "            \n",
    "find_cat(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(train_data.values, train_labels.values, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st.shape,y_train_st.shape,y_train_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.RidgeClassifier(alpha=10.0)\n",
    "#svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')\n",
    "#\n",
    "clfs = [create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.LogisticRegression(solver='liblinear',class_weight=None,tol=1e-05, penalty='l2')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.RidgeClassifier(alpha=10.0)),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,ensemble.GradientBoostingClassifier(learning_rate= 0.1, max_depth= 3, max_features='auto', n_estimators= 32))\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train = np.zeros((X_train_st.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    for i, (train_, test_) in enumerate(kf.split(X_train_st, y_train_st)):\n",
    "        print (\"Fold\", i)\n",
    "        X_tr = X_train_st[train_]\n",
    "        y_tr = y_train_st[train_]\n",
    "        X_te = X_train_st[test_]\n",
    "        y_te = y_train_st[test_]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        print('------------------------',type(clf[1]))\n",
    "        if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "            print('----------SVM/RidgeCl-------')\n",
    "            y_submission = clf.predict(X_te)\n",
    "        else:\n",
    "            print('----------Other-------')\n",
    "            y_submission = clf.predict_proba(X_te)[:, 1]\n",
    "        dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(clf[1],svm.SVC),\n",
    "type(clf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = linear_model.RidgeClassifier(class_weight=None,tol=1e-05, random_state=11)\n",
    "ls = cross_val_score(clf2, dataset_blend_train, y_train_st, cv=5, scoring='accuracy')\n",
    "print(ls)\n",
    "np.mean(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.fit(dataset_blend_train, y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf2.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест для стекинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "X_meta = np.zeros((X_test_st.shape[0],len(clfs)))\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    #for i, (train_, test_) in enumerate(kf.split(train_data, train_labels)):\n",
    "    #    print (\"Fold\", i)\n",
    "    #    X_tr = train_data.values[train_]\n",
    "    #    y_tr = train_labels[train_]\n",
    "    #    X_te = train_data.values[test_]\n",
    "    #    y_te = train_labels[test_]\n",
    "    #    clf_pipeline=create_estimator(numeric_data_indices,categorical_data_indices,clf)\n",
    "    #    clf_pipeline.fit(X_tr, y_tr)\n",
    "    print('------------------------',type(clf[1]))\n",
    "    if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "        print('----------SVM/RidgeCl-------')\n",
    "        #y_submission = clf_.predict(X_te)\n",
    "        X_meta[:, j] = clf.predict(X_test_st)\n",
    "    else:\n",
    "        print('----------Other-------')\n",
    "        #y_submission = clf_pipeline.predict_proba(X_te)[:, 1]\n",
    "        X_meta[:, j] = clf.predict_proba(X_test_st)[:, 1]\n",
    "    #dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape,X_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_meta=clf2.predict(X_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_st, pred_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стекинг для ответа kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.RidgeClassifier(alpha=10.0)\n",
    "#svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')\n",
    "#\n",
    "clfs = [create_estimator(numeric_data_indices,categorical_data_indices,svm.SVC(gamma='auto',C=0.8, decision_function_shape='ovo', kernel= 'linear')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.LogisticRegression(solver='liblinear',class_weight=None,tol=1e-05, penalty='l2')),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,linear_model.RidgeClassifier(alpha=10.0)),\n",
    "        create_estimator(numeric_data_indices,categorical_data_indices,ensemble.GradientBoostingClassifier(learning_rate= 0.1, max_depth= 3, max_features='auto', n_estimators= 32))\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st_kaggle=train_data.values\n",
    "y_train_st_kaggle=train_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train = np.zeros((X_train_st_kaggle.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    for i, (train_, test_) in enumerate(kf.split(X_train_st_kaggle, y_train_st_kaggle)):\n",
    "        print (\"Fold\", i)\n",
    "        X_tr = X_train_st_kaggle[train_]\n",
    "        y_tr = y_train_st_kaggle[train_]\n",
    "        X_te = X_train_st_kaggle[test_]\n",
    "        y_te = y_train_st_kaggle[test_]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        print('------------------------',type(clf[1]))\n",
    "        if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "            print('----------SVM/RidgeCl-------')\n",
    "            y_submission = clf.predict(X_te)\n",
    "        else:\n",
    "            print('----------Other-------')\n",
    "            y_submission = clf.predict_proba(X_te)[:, 1]\n",
    "        dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_kaggle = linear_model.RidgeClassifier(class_weight=None,tol=1e-05, random_state=11)\n",
    "clf_meta_kaggle.fit(dataset_blend_train, y_train_st_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг test для kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st_kaggle=test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = model_selection.StratifiedKFold(n_splits=5,shuffle=False)\n",
    "X_meta = np.zeros((X_test_st_kaggle.shape[0],len(clfs)))\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf[1])\n",
    "    #for i, (train_, test_) in enumerate(kf.split(train_data, train_labels)):\n",
    "    #    print (\"Fold\", i)\n",
    "    #    X_tr = train_data.values[train_]\n",
    "    #    y_tr = train_labels[train_]\n",
    "    #    X_te = train_data.values[test_]\n",
    "    #    y_te = train_labels[test_]\n",
    "    #    clf_pipeline=create_estimator(numeric_data_indices,categorical_data_indices,clf)\n",
    "    #    clf_pipeline.fit(X_tr, y_tr)\n",
    "    print('------------------------',type(clf[1]))\n",
    "    if isinstance(clf[1],svm.SVC) or isinstance(clf[1],linear_model.ridge.RidgeClassifier):\n",
    "        print('----------SVM/RidgeCl-------')\n",
    "        #y_submission = clf_.predict(X_te)\n",
    "        X_meta[:, j] = clf.predict(X_test_st_kaggle)\n",
    "    else:\n",
    "        print('----------Other-------')\n",
    "        #y_submission = clf_pipeline.predict_proba(X_te)[:, 1]\n",
    "        X_meta[:, j] = clf.predict_proba(X_test_st_kaggle)[:, 1]\n",
    "    #dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=clf_meta_kaggle.predict(X_meta)\n",
    "submission = pd.DataFrame({'PassengerId':raw_test_data.PassengerId,'Survived':result})\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'titanic16_stack.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data_columns = ['Name','Ticket','Cabin']\n",
    "categorical_data_columns = ['Pclass','Sex','Embarked','Salutation','Age_Range', 'Fare_Category','Family_Size','Salutation_type']\n",
    "numeric_data_columns = ['Age', 'SibSp', 'Parch', 'Fare','Family','isCabin','Log_Fare']\n",
    "#numeric_data_columns = ['Family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
